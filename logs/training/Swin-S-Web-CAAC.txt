You have chosen to seed training. This will slow down your training!
Construct dataset.
112471 training items found.
14059 valid items found.
Construct model.
Model(
  (backbone): SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(1, 4), stride=(1, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        dim=96, input_resolution=(32, 64), depth=2
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=96, window_size=(2, 8), num_heads=3
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=96, window_size=(2, 8), num_heads=3
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          input_resolution=(32, 64), dim=96
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        dim=192, input_resolution=(16, 32), depth=2
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=192, window_size=(2, 8), num_heads=6
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=192, window_size=(2, 8), num_heads=6
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          input_resolution=(16, 32), dim=192
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        dim=384, input_resolution=(8, 16), depth=18
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
  )
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (decoder): PositionAttention(
    (k_encoder): Sequential(
      (0): Sequential(
        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (2): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (k_decoder): Sequential(
      (0): Sequential(
        (0): Upsample(scale_factor=2.0, mode=nearest)
        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Upsample(scale_factor=2.0, mode=nearest)
        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace=True)
      )
      (2): Sequential(
        (0): Upsample(size=(4, 32), mode=nearest)
        (1): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace=True)
      )
    )
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0, inplace=False)
    )
    (project): Linear(in_features=512, out_features=512, bias=True)
  )
  (cls): Linear(in_features=512, out_features=7935, bias=True)
)
The parameters size of model is 41.312897 MB
Construct learner.
Use 4 GPUs.
Start training.
epoch 1 iter 292: loss = 11.7364, smooth loss = 12.0427, ce loss = 4.9869, contrastive loss = 1.7626, lr = 0.00022400000000000002
epoch 2 iter 584: loss = 11.0977, smooth loss = 11.4613, ce loss = 4.6844, contrastive loss = 1.7289, lr = 0.0006079999999999999
epoch 3 iter 876: loss = 10.5869, smooth loss = 10.9936, ce loss = 4.4397, contrastive loss = 1.7075, lr = 0.0008
epoch 4 iter 1168: loss = 9.9073, smooth loss = 10.0107, ce loss = 4.1318, contrastive loss = 1.6438, lr = 0.0007998558116451099
epoch 5 iter 1460: loss = 8.5154, smooth loss = 8.8381, ce loss = 3.4472, contrastive loss = 1.6211, lr = 0.0007994233505322638
epoch 6 iter 1752: loss = 7.8507, smooth loss = 7.9922, ce loss = 3.1150, contrastive loss = 1.6206, lr = 0.000798702928441991
epoch 7 iter 2044: loss = 6.8895, smooth loss = 7.4392, ce loss = 2.6577, contrastive loss = 1.5741, lr = 0.000797695064758749
epoch 8 iter 2336: loss = 6.8564, smooth loss = 6.9871, ce loss = 2.6457, contrastive loss = 1.5650, lr = 0.0007964004860964767
epoch 9 iter 2628: loss = 6.6135, smooth loss = 6.6707, ce loss = 2.5233, contrastive loss = 1.5668, lr = 0.0007948201257747449
epoch 10 iter 2920: loss = 6.2778, smooth loss = 6.3906, ce loss = 2.3631, contrastive loss = 1.5517, lr = 0.000792955123145886
epoch 11 iter 3212: loss = 6.0629, smooth loss = 6.1753, ce loss = 2.2629, contrastive loss = 1.5371, lr = 0.0007908068227735828
epoch 12 iter 3504: loss = 6.0485, smooth loss = 5.9891, ce loss = 2.2585, contrastive loss = 1.5316, lr = 0.000788376773463513
epoch 13 iter 3796: loss = 5.6267, smooth loss = 5.8180, ce loss = 2.0598, contrastive loss = 1.5071, lr = 0.0007856667271467458
epoch 14 iter 4088: loss = 5.6667, smooth loss = 5.6771, ce loss = 2.0850, contrastive loss = 1.4968, lr = 0.0007826786376166968
epoch 15 iter 4380: loss = 5.1872, smooth loss = 5.5309, ce loss = 1.8622, contrastive loss = 1.4627, lr = 0.0007794146591205511
epoch 16 iter 4672: loss = 5.2842, smooth loss = 5.3809, ce loss = 1.9028, contrastive loss = 1.4785, lr = 0.0007758771448061701
epoch 17 iter 4964: loss = 5.2486, smooth loss = 5.2899, ce loss = 1.8786, contrastive loss = 1.4915, lr = 0.0007720686450256023
epoch 18 iter 5256: loss = 4.9522, smooth loss = 5.2162, ce loss = 1.7302, contrastive loss = 1.4918, lr = 0.0007679919054964199
epoch 19 iter 5548: loss = 4.7010, smooth loss = 5.1049, ce loss = 1.6278, contrastive loss = 1.4455, lr = 0.0007636498653222099
epoch 20 iter 5840: loss = 4.4202, smooth loss = 5.0445, ce loss = 1.5099, contrastive loss = 1.4003, lr = 0.0007590456548736415
Save model train-seed-42-FuDan-Scene-32-256-bs-384-lr-0.0008-d_model-512-epoch-120-decay-cos-grad-clip-20-AdamW-wd-0.15-PA-decoder-max-len-40-sup_con-1.0-ce-2.0-temperature-0.15-warm_up-0.025_20_5840
epoch 21 iter 6132: loss = 5.3641, smooth loss = 4.9734, ce loss = 1.9315, contrastive loss = 1.5011, lr = 0.0007541825935316429
epoch 22 iter 6424: loss = 4.3451, smooth loss = 4.8902, ce loss = 1.4588, contrastive loss = 1.4274, lr = 0.0007490641872943116
epoch 23 iter 6716: loss = 4.5006, smooth loss = 4.8140, ce loss = 1.5314, contrastive loss = 1.4379, lr = 0.0007436941262492827
epoch 24 iter 7008: loss = 4.7252, smooth loss = 4.7505, ce loss = 1.6279, contrastive loss = 1.4694, lr = 0.0007380762819133811
epoch 25 iter 7300: loss = 4.5567, smooth loss = 4.7436, ce loss = 1.5550, contrastive loss = 1.4468, lr = 0.0007322147044414715
epoch 26 iter 7592: loss = 4.4824, smooth loss = 4.5939, ce loss = 1.5251, contrastive loss = 1.4322, lr = 0.0007261136197065211
epoch 27 iter 7884: loss = 3.9101, smooth loss = 4.5696, ce loss = 1.2593, contrastive loss = 1.3916, lr = 0.0007197774262529791
epoch 28 iter 8176: loss = 4.5392, smooth loss = 4.5031, ce loss = 1.5487, contrastive loss = 1.4419, lr = 0.0007132106921256691
epoch 29 iter 8468: loss = 4.1277, smooth loss = 4.4373, ce loss = 1.3547, contrastive loss = 1.4183, lr = 0.0007064181515764822
epoch 30 iter 8760: loss = 4.0958, smooth loss = 4.4567, ce loss = 1.3458, contrastive loss = 1.4043, lr = 0.0006994047016512434
epoch 31 iter 9052: loss = 3.8894, smooth loss = 4.3375, ce loss = 1.2488, contrastive loss = 1.3918, lr = 0.0006921753986592118
epoch 32 iter 9344: loss = 4.0795, smooth loss = 4.3463, ce loss = 1.3333, contrastive loss = 1.4129, lr = 0.0006847354545277624
epoch 33 iter 9636: loss = 4.4009, smooth loss = 4.2938, ce loss = 1.4681, contrastive loss = 1.4648, lr = 0.0006770902330448742
epoch 34 iter 9928: loss = 3.7249, smooth loss = 4.2456, ce loss = 1.1814, contrastive loss = 1.3622, lr = 0.0006692452459921362
epoch 35 iter 10220: loss = 4.2598, smooth loss = 4.1688, ce loss = 1.4136, contrastive loss = 1.4326, lr = 0.000661206149171058
epoch 36 iter 10512: loss = 4.0481, smooth loss = 4.1670, ce loss = 1.3203, contrastive loss = 1.4074, lr = 0.0006529787383255499
epoch 37 iter 10804: loss = 3.9287, smooth loss = 4.1087, ce loss = 1.2747, contrastive loss = 1.3793, lr = 0.0006445689449635119
epoch 38 iter 11096: loss = 4.2860, smooth loss = 4.0593, ce loss = 1.4297, contrastive loss = 1.4267, lr = 0.0006359828320805452
epoch 39 iter 11388: loss = 3.6895, smooth loss = 4.0402, ce loss = 1.1522, contrastive loss = 1.3852, lr = 0.0006272265897888675
epoch 40 iter 11680: loss = 3.6411, smooth loss = 3.9759, ce loss = 1.1390, contrastive loss = 1.3630, lr = 0.0006183065308545855
Save model train-seed-42-FuDan-Scene-32-256-bs-384-lr-0.0008-d_model-512-epoch-120-decay-cos-grad-clip-20-AdamW-wd-0.15-PA-decoder-max-len-40-sup_con-1.0-ce-2.0-temperature-0.15-warm_up-0.025_40_11680
epoch 41 iter 11972: loss = 3.5401, smooth loss = 3.9476, ce loss = 1.0867, contrastive loss = 1.3667, lr = 0.0006092290861465388
epoch 42 iter 12264: loss = 3.5097, smooth loss = 3.9637, ce loss = 1.0724, contrastive loss = 1.3649, lr = 0.0006000008
epoch 43 iter 12556: loss = 3.6879, smooth loss = 3.8706, ce loss = 1.1432, contrastive loss = 1.4016, lr = 0.0005906283254985711
epoch 44 iter 12848: loss = 3.7501, smooth loss = 3.8664, ce loss = 1.1817, contrastive loss = 1.3866, lr = 0.0005811184196776785
epoch 45 iter 13140: loss = 3.8217, smooth loss = 3.8586, ce loss = 1.1994, contrastive loss = 1.4229, lr = 0.0005714779386531235
epoch 46 iter 13432: loss = 3.2900, smooth loss = 3.7795, ce loss = 0.9713, contrastive loss = 1.3473, lr = 0.0005617138326782039
epoch 47 iter 13724: loss = 3.6946, smooth loss = 3.7786, ce loss = 1.1640, contrastive loss = 1.3666, lr = 0.0005518331411329647
epoch 48 iter 14016: loss = 3.4108, smooth loss = 3.7147, ce loss = 1.0262, contrastive loss = 1.3585, lr = 0.000541842987449195
epoch 49 iter 14308: loss = 3.6531, smooth loss = 3.7258, ce loss = 1.1414, contrastive loss = 1.3703, lr = 0.0005317505739748281
epoch 50 iter 14600: loss = 3.2351, smooth loss = 3.6525, ce loss = 0.9444, contrastive loss = 1.3464, lr = 0.0005215631767814466
epoch 51 iter 14892: loss = 3.6709, smooth loss = 3.6637, ce loss = 1.1589, contrastive loss = 1.3531, lr = 0.0005112881404186389
epoch 52 iter 15184: loss = 3.4939, smooth loss = 3.5933, ce loss = 1.0639, contrastive loss = 1.3661, lr = 0.0005009328726189833
epoch 53 iter 15476: loss = 3.4495, smooth loss = 3.5832, ce loss = 1.0372, contrastive loss = 1.3751, lr = 0.0004905048389574851
epoch 54 iter 15768: loss = 3.4043, smooth loss = 3.5928, ce loss = 1.0201, contrastive loss = 1.3640, lr = 0.00048001155746930777
epoch 55 iter 16060: loss = 3.5249, smooth loss = 3.5435, ce loss = 1.0744, contrastive loss = 1.3761, lr = 0.00046946059322968797
epoch 56 iter 16352: loss = 3.4014, smooth loss = 3.5125, ce loss = 1.0233, contrastive loss = 1.3548, lr = 0.00045885955289993313
epoch 57 iter 16644: loss = 3.4983, smooth loss = 3.4948, ce loss = 1.0588, contrastive loss = 1.3808, lr = 0.0004482160792434408
epoch 58 iter 16936: loss = 3.1533, smooth loss = 3.4516, ce loss = 0.9147, contrastive loss = 1.3239, lr = 0.0004375378456156887
epoch 59 iter 17228: loss = 3.1972, smooth loss = 3.4117, ce loss = 0.9261, contrastive loss = 1.3451, lr = 0.00042683255043216993
epoch 60 iter 17520: loss = 3.3430, smooth loss = 3.3723, ce loss = 0.9780, contrastive loss = 1.3869, lr = 0.0004161079116182619
Save model train-seed-42-FuDan-Scene-32-256-bs-384-lr-0.0008-d_model-512-epoch-120-decay-cos-grad-clip-20-AdamW-wd-0.15-PA-decoder-max-len-40-sup_con-1.0-ce-2.0-temperature-0.15-warm_up-0.025_60_17520
epoch 61 iter 17812: loss = 3.6008, smooth loss = 3.3902, ce loss = 1.1090, contrastive loss = 1.3828, lr = 0.0004053716610450289
epoch 62 iter 18104: loss = 3.2812, smooth loss = 3.3422, ce loss = 0.9767, contrastive loss = 1.3277, lr = 0.0003946315389549712
epoch 63 iter 18396: loss = 3.2237, smooth loss = 3.3235, ce loss = 0.9588, contrastive loss = 1.3062, lr = 0.00038389528838173823
epoch 64 iter 18688: loss = 3.5628, smooth loss = 3.3064, ce loss = 1.0920, contrastive loss = 1.3787, lr = 0.00037317064956783006
epoch 65 iter 18980: loss = 3.1864, smooth loss = 3.2595, ce loss = 0.9279, contrastive loss = 1.3306, lr = 0.0003624653543843114
epoch 66 iter 19272: loss = 2.7046, smooth loss = 3.2080, ce loss = 0.7119, contrastive loss = 1.2808, lr = 0.00035178712075655926
epoch 67 iter 19564: loss = 3.2538, smooth loss = 3.1856, ce loss = 0.9410, contrastive loss = 1.3719, lr = 0.0003411436471000669
epoch 68 iter 19856: loss = 3.2635, smooth loss = 3.1718, ce loss = 0.9569, contrastive loss = 1.3496, lr = 0.0003305426067703122
epoch 69 iter 20148: loss = 2.9614, smooth loss = 3.1500, ce loss = 0.8274, contrastive loss = 1.3066, lr = 0.00031999164253069233
average data time = 0.0297s, average running time = 1.4089s
epoch 69 iter 20148: eval loss = 1.3495,  ccr = 0.7325,  cwr = 0.6206,  ted = 17186.0000,  ned = 3065.5708,  ted/w = 1.2224, 
Better model found at epoch 69, iter 20148 with accuracy value: 0.6206.
epoch 70 iter 20440: loss = 2.9785, smooth loss = 3.1176, ce loss = 0.8360, contrastive loss = 1.3064, lr = 0.0003094983610425151
average data time = 0.0297s, average running time = 1.4113s
epoch 70 iter 20440: eval loss = 1.3194,  ccr = 0.7331,  cwr = 0.6192,  ted = 17510.0000,  ned = 3125.3885,  ted/w = 1.2455, 
epoch 71 iter 20732: loss = 3.0421, smooth loss = 3.0601, ce loss = 0.8557, contrastive loss = 1.3308, lr = 0.0002990703273810167
average data time = 0.0296s, average running time = 1.4132s
epoch 71 iter 20732: eval loss = 1.3379,  ccr = 0.7351,  cwr = 0.6239,  ted = 17136.0000,  ned = 3076.6739,  ted/w = 1.2189, 
Better model found at epoch 71, iter 20732 with accuracy value: 0.6239.
epoch 72 iter 21024: loss = 2.5902, smooth loss = 3.0460, ce loss = 0.6610, contrastive loss = 1.2681, lr = 0.0002887150595813612
average data time = 0.0296s, average running time = 1.4153s
epoch 72 iter 21024: eval loss = 1.3456,  ccr = 0.7369,  cwr = 0.6252,  ted = 16764.0000,  ned = 3003.8804,  ted/w = 1.1924, 
Better model found at epoch 72, iter 21024 with accuracy value: 0.6252.
epoch 73 iter 21316: loss = 2.8007, smooth loss = 3.0380, ce loss = 0.7455, contrastive loss = 1.3096, lr = 0.0002784400232185534
average data time = 0.0296s, average running time = 1.4172s
epoch 73 iter 21316: eval loss = 1.3402,  ccr = 0.7390,  cwr = 0.6244,  ted = 16630.0000,  ned = 2973.7115,  ted/w = 1.1829, 
epoch 74 iter 21608: loss = 3.0336, smooth loss = 3.0130, ce loss = 0.8521, contrastive loss = 1.3294, lr = 0.0002682526260251721
average data time = 0.0295s, average running time = 1.4190s
epoch 74 iter 21608: eval loss = 1.3291,  ccr = 0.7385,  cwr = 0.6266,  ted = 17163.0000,  ned = 3016.2686,  ted/w = 1.2208, 
Better model found at epoch 74, iter 21608 with accuracy value: 0.6266.
epoch 75 iter 21900: loss = 3.0562, smooth loss = 3.0129, ce loss = 0.8664, contrastive loss = 1.3234, lr = 0.00025816021255080504
average data time = 0.0296s, average running time = 1.4210s
epoch 75 iter 21900: eval loss = 1.3377,  ccr = 0.7370,  cwr = 0.6271,  ted = 16695.0000,  ned = 2998.1779,  ted/w = 1.1875, 
Better model found at epoch 75, iter 21900 with accuracy value: 0.6271.
epoch 76 iter 22192: loss = 2.6308, smooth loss = 2.9532, ce loss = 0.6635, contrastive loss = 1.3037, lr = 0.00024817005886703536
average data time = 0.0295s, average running time = 1.4230s
epoch 76 iter 22192: eval loss = 1.3723,  ccr = 0.7400,  cwr = 0.6271,  ted = 16739.0000,  ned = 3030.3875,  ted/w = 1.1906, 
Better model found at epoch 76, iter 22192 with accuracy value: 0.6271.
epoch 77 iter 22484: loss = 3.0074, smooth loss = 2.9564, ce loss = 0.8355, contrastive loss = 1.3363, lr = 0.0002382893673217962
average data time = 0.0295s, average running time = 1.4249s
epoch 77 iter 22484: eval loss = 1.3215,  ccr = 0.7388,  cwr = 0.6277,  ted = 16668.0000,  ned = 3000.3623,  ted/w = 1.1856, 
Better model found at epoch 77, iter 22484 with accuracy value: 0.6277.
epoch 78 iter 22776: loss = 2.8575, smooth loss = 2.9684, ce loss = 0.7693, contrastive loss = 1.3190, lr = 0.00022852526134687652
average data time = 0.0295s, average running time = 1.4269s
epoch 78 iter 22776: eval loss = 1.3583,  ccr = 0.7380,  cwr = 0.6274,  ted = 16827.0000,  ned = 2998.3792,  ted/w = 1.1969, 
epoch 79 iter 23068: loss = 2.9912, smooth loss = 2.9194, ce loss = 0.8244, contrastive loss = 1.3425, lr = 0.00021888478032232176
average data time = 0.0295s, average running time = 1.4286s
epoch 79 iter 23068: eval loss = 1.3456,  ccr = 0.7406,  cwr = 0.6301,  ted = 16543.0000,  ned = 2934.1321,  ted/w = 1.1767, 
Better model found at epoch 79, iter 23068 with accuracy value: 0.6301.
epoch 80 iter 23360: loss = 2.9487, smooth loss = 2.8999, ce loss = 0.8116, contrastive loss = 1.3255, lr = 0.0002093748745014289
average data time = 0.0295s, average running time = 1.4305s
epoch 80 iter 23360: eval loss = 1.3335,  ccr = 0.7410,  cwr = 0.6308,  ted = 16593.0000,  ned = 2973.0097,  ted/w = 1.1802, 
Better model found at epoch 80, iter 23360 with accuracy value: 0.6308.
Save model train-seed-42-FuDan-Scene-32-256-bs-384-lr-0.0008-d_model-512-epoch-120-decay-cos-grad-clip-20-AdamW-wd-0.15-PA-decoder-max-len-40-sup_con-1.0-ce-2.0-temperature-0.15-warm_up-0.025_80_23360
epoch 81 iter 23652: loss = 2.7348, smooth loss = 2.8583, ce loss = 0.7147, contrastive loss = 1.3054, lr = 0.0002000024000000001
average data time = 0.0295s, average running time = 1.4325s
epoch 81 iter 23652: eval loss = 1.3507,  ccr = 0.7425,  cwr = 0.6339,  ted = 16433.0000,  ned = 2957.0738,  ted/w = 1.1689, 
Better model found at epoch 81, iter 23652 with accuracy value: 0.6339.
epoch 82 iter 23944: loss = 2.7544, smooth loss = 2.8352, ce loss = 0.7325, contrastive loss = 1.2893, lr = 0.00019077411385346127
average data time = 0.0295s, average running time = 1.4343s
epoch 82 iter 23944: eval loss = 1.3393,  ccr = 0.7451,  cwr = 0.6348,  ted = 16312.0000,  ned = 2922.9910,  ted/w = 1.1603, 
Better model found at epoch 82, iter 23944 with accuracy value: 0.6348.
epoch 83 iter 24236: loss = 2.9478, smooth loss = 2.8251, ce loss = 0.8044, contrastive loss = 1.3390, lr = 0.00018169666914541447
average data time = 0.0295s, average running time = 1.4360s
epoch 83 iter 24236: eval loss = 1.3341,  ccr = 0.7431,  cwr = 0.6326,  ted = 16485.0000,  ned = 2922.0806,  ted/w = 1.1726, 
epoch 84 iter 24528: loss = 2.7746, smooth loss = 2.7773, ce loss = 0.7344, contrastive loss = 1.3058, lr = 0.0001727766102111325
average data time = 0.0295s, average running time = 1.4375s
epoch 84 iter 24528: eval loss = 1.3342,  ccr = 0.7475,  cwr = 0.6375,  ted = 16153.0000,  ned = 2874.3723,  ted/w = 1.1489, 
Better model found at epoch 84, iter 24528 with accuracy value: 0.6375.
epoch 85 iter 24820: loss = 2.7278, smooth loss = 2.7742, ce loss = 0.7170, contrastive loss = 1.2939, lr = 0.000164020367919455
average data time = 0.0295s, average running time = 1.4391s
epoch 85 iter 24820: eval loss = 1.3487,  ccr = 0.7427,  cwr = 0.6345,  ted = 16379.0000,  ned = 2940.8342,  ted/w = 1.1650, 
epoch 86 iter 25112: loss = 2.5700, smooth loss = 2.7436, ce loss = 0.6503, contrastive loss = 1.2695, lr = 0.00015543425503648805
average data time = 0.0295s, average running time = 1.4406s
epoch 86 iter 25112: eval loss = 1.3445,  ccr = 0.7436,  cwr = 0.6386,  ted = 16040.0000,  ned = 2875.8120,  ted/w = 1.1409, 
Better model found at epoch 86, iter 25112 with accuracy value: 0.6386.
epoch 87 iter 25404: loss = 2.7271, smooth loss = 2.7454, ce loss = 0.7043, contrastive loss = 1.3185, lr = 0.0001470244616744501
average data time = 0.0295s, average running time = 1.4422s
epoch 87 iter 25404: eval loss = 1.3316,  ccr = 0.7468,  cwr = 0.6384,  ted = 16020.0000,  ned = 2901.2285,  ted/w = 1.1395, 
epoch 88 iter 25696: loss = 2.8417, smooth loss = 2.7104, ce loss = 0.7603, contrastive loss = 1.3212, lr = 0.00013879705082894204
average data time = 0.0295s, average running time = 1.4436s
epoch 88 iter 25696: eval loss = 1.3319,  ccr = 0.7467,  cwr = 0.6359,  ted = 16103.0000,  ned = 2881.1218,  ted/w = 1.1454, 
epoch 89 iter 25988: loss = 2.7937, smooth loss = 2.7017, ce loss = 0.7491, contrastive loss = 1.2955, lr = 0.00013075795400786374
average data time = 0.0295s, average running time = 1.4449s
epoch 89 iter 25988: eval loss = 1.3472,  ccr = 0.7459,  cwr = 0.6360,  ted = 16149.0000,  ned = 2901.4676,  ted/w = 1.1487, 
epoch 90 iter 26280: loss = 2.4476, smooth loss = 2.6600, ce loss = 0.5884, contrastive loss = 1.2708, lr = 0.00012291296695512586
average data time = 0.0295s, average running time = 1.4462s
epoch 90 iter 26280: eval loss = 1.3239,  ccr = 0.7492,  cwr = 0.6392,  ted = 16045.0000,  ned = 2913.5664,  ted/w = 1.1413, 
Better model found at epoch 90, iter 26280 with accuracy value: 0.6392.
epoch 91 iter 26572: loss = 2.4535, smooth loss = 2.6329, ce loss = 0.5965, contrastive loss = 1.2605, lr = 0.00011526774547223771
average data time = 0.0295s, average running time = 1.4477s
epoch 91 iter 26572: eval loss = 1.3286,  ccr = 0.7494,  cwr = 0.6429,  ted = 15795.0000,  ned = 2828.1323,  ted/w = 1.1235, 
Better model found at epoch 91, iter 26572 with accuracy value: 0.6429.
epoch 92 iter 26864: loss = 2.4821, smooth loss = 2.6364, ce loss = 0.5952, contrastive loss = 1.2917, lr = 0.00010782780134078822
average data time = 0.0295s, average running time = 1.4490s
epoch 92 iter 26864: eval loss = 1.3364,  ccr = 0.7503,  cwr = 0.6447,  ted = 15807.0000,  ned = 2847.0162,  ted/w = 1.1243, 
Better model found at epoch 92, iter 26864 with accuracy value: 0.6447.
epoch 93 iter 27156: loss = 2.5525, smooth loss = 2.6165, ce loss = 0.6406, contrastive loss = 1.2713, lr = 0.00010059849834875659
average data time = 0.0295s, average running time = 1.4504s
epoch 93 iter 27156: eval loss = 1.3484,  ccr = 0.7484,  cwr = 0.6419,  ted = 15935.0000,  ned = 2860.5181,  ted/w = 1.1334, 
epoch 94 iter 27448: loss = 2.6054, smooth loss = 2.5870, ce loss = 0.6552, contrastive loss = 1.2950, lr = 9.358504842351783e-05
average data time = 0.0295s, average running time = 1.4516s
epoch 94 iter 27448: eval loss = 1.3522,  ccr = 0.7473,  cwr = 0.6403,  ted = 15723.0000,  ned = 2830.8891,  ted/w = 1.1184, 
epoch 95 iter 27740: loss = 2.6193, smooth loss = 2.5963, ce loss = 0.6610, contrastive loss = 1.2973, lr = 8.679250787433099e-05
average data time = 0.0295s, average running time = 1.4528s
epoch 95 iter 27740: eval loss = 1.3541,  ccr = 0.7505,  cwr = 0.6454,  ted = 15801.0000,  ned = 2844.8758,  ted/w = 1.1239, 
Better model found at epoch 95, iter 27740 with accuracy value: 0.6454.
epoch 96 iter 28032: loss = 2.7932, smooth loss = 2.5549, ce loss = 0.7305, contrastive loss = 1.3322, lr = 8.022577374702106e-05
average data time = 0.0294s, average running time = 1.4541s
epoch 96 iter 28032: eval loss = 1.3510,  ccr = 0.7500,  cwr = 0.6410,  ted = 15792.0000,  ned = 2853.3265,  ted/w = 1.1233, 
epoch 97 iter 28324: loss = 2.6802, smooth loss = 2.5312, ce loss = 0.6968, contrastive loss = 1.2866, lr = 7.388958029347893e-05
average data time = 0.0294s, average running time = 1.4553s
epoch 97 iter 28324: eval loss = 1.3457,  ccr = 0.7503,  cwr = 0.6448,  ted = 15597.0000,  ned = 2823.0414,  ted/w = 1.1094, 
epoch 98 iter 28616: loss = 2.6495, smooth loss = 2.5553, ce loss = 0.6669, contrastive loss = 1.3156, lr = 6.778849555852853e-05
average data time = 0.0294s, average running time = 1.4565s
epoch 98 iter 28616: eval loss = 1.3460,  ccr = 0.7516,  cwr = 0.6462,  ted = 15626.0000,  ned = 2813.1660,  ted/w = 1.1115, 
Better model found at epoch 98, iter 28616 with accuracy value: 0.6462.
epoch 99 iter 28908: loss = 2.2803, smooth loss = 2.4839, ce loss = 0.5123, contrastive loss = 1.2556, lr = 6.192691808661902e-05
average data time = 0.0294s, average running time = 1.4576s
epoch 99 iter 28908: eval loss = 1.3463,  ccr = 0.7504,  cwr = 0.6426,  ted = 15627.0000,  ned = 2840.3456,  ted/w = 1.1115, 
epoch 100 iter 29200: loss = 2.6402, smooth loss = 2.5123, ce loss = 0.6606, contrastive loss = 1.3189, lr = 5.630907375071737e-05
average data time = 0.0294s, average running time = 1.4587s
epoch 100 iter 29200: eval loss = 1.3536,  ccr = 0.7509,  cwr = 0.6463,  ted = 15615.0000,  ned = 2812.0010,  ted/w = 1.1107, 
Better model found at epoch 100, iter 29200 with accuracy value: 0.6463.
Save model train-seed-42-FuDan-Scene-32-256-bs-384-lr-0.0008-d_model-512-epoch-120-decay-cos-grad-clip-20-AdamW-wd-0.15-PA-decoder-max-len-40-sup_con-1.0-ce-2.0-temperature-0.15-warm_up-0.025_100_29200
epoch 101 iter 29492: loss = 2.4401, smooth loss = 2.4740, ce loss = 0.5976, contrastive loss = 1.2450, lr = 5.093901270568848e-05
average data time = 0.0294s, average running time = 1.4599s
epoch 101 iter 29492: eval loss = 1.3661,  ccr = 0.7523,  cwr = 0.6459,  ted = 15546.0000,  ned = 2842.4022,  ted/w = 1.1058, 
epoch 102 iter 29784: loss = 2.6962, smooth loss = 2.4662, ce loss = 0.6871, contrastive loss = 1.3220, lr = 4.582060646835713e-05
average data time = 0.0294s, average running time = 1.4609s
epoch 102 iter 29784: eval loss = 1.3470,  ccr = 0.7524,  cwr = 0.6468,  ted = 15587.0000,  ned = 2828.9974,  ted/w = 1.1087, 
Better model found at epoch 102, iter 29784 with accuracy value: 0.6468.
epoch 103 iter 30076: loss = 2.5505, smooth loss = 2.4701, ce loss = 0.6351, contrastive loss = 1.2803, lr = 4.09575451263587e-05
average data time = 0.0293s, average running time = 1.4619s
epoch 103 iter 30076: eval loss = 1.3437,  ccr = 0.7541,  cwr = 0.6481,  ted = 15426.0000,  ned = 2793.7567,  ted/w = 1.0972, 
Better model found at epoch 103, iter 30076 with accuracy value: 0.6481.
epoch 104 iter 30368: loss = 2.5463, smooth loss = 2.4483, ce loss = 0.6287, contrastive loss = 1.2889, lr = 3.635333467779016e-05
average data time = 0.0293s, average running time = 1.4629s
epoch 104 iter 30368: eval loss = 1.3600,  ccr = 0.7548,  cwr = 0.6487,  ted = 15309.0000,  ned = 2779.6441,  ted/w = 1.0889, 
Better model found at epoch 104, iter 30368 with accuracy value: 0.6487.
epoch 105 iter 30660: loss = 2.7060, smooth loss = 2.4698, ce loss = 0.7040, contrastive loss = 1.2979, lr = 3.201129450358016e-05
average data time = 0.0293s, average running time = 1.4638s
epoch 105 iter 30660: eval loss = 1.3596,  ccr = 0.7546,  cwr = 0.6510,  ted = 15289.0000,  ned = 2767.0168,  ted/w = 1.0875, 
Better model found at epoch 105, iter 30660 with accuracy value: 0.6510.
epoch 106 iter 30952: loss = 2.5162, smooth loss = 2.4522, ce loss = 0.6220, contrastive loss = 1.2722, lr = 2.7934554974397916e-05
average data time = 0.0292s, average running time = 1.4647s
epoch 106 iter 30952: eval loss = 1.3650,  ccr = 0.7539,  cwr = 0.6502,  ted = 15347.0000,  ned = 2779.0597,  ted/w = 1.0916, 
epoch 107 iter 31244: loss = 2.4482, smooth loss = 2.4139, ce loss = 0.5933, contrastive loss = 1.2616, lr = 2.412605519382993e-05
average data time = 0.0293s, average running time = 1.4655s
epoch 107 iter 31244: eval loss = 1.3540,  ccr = 0.7533,  cwr = 0.6493,  ted = 15376.0000,  ned = 2760.3325,  ted/w = 1.0937, 
epoch 108 iter 31536: loss = 2.4709, smooth loss = 2.4306, ce loss = 0.5966, contrastive loss = 1.2777, lr = 2.0588540879448922e-05
average data time = 0.0292s, average running time = 1.4663s
epoch 108 iter 31536: eval loss = 1.3533,  ccr = 0.7550,  cwr = 0.6513,  ted = 15378.0000,  ned = 2771.8626,  ted/w = 1.0938, 
Better model found at epoch 108, iter 31536 with accuracy value: 0.6513.
epoch 109 iter 31828: loss = 2.1126, smooth loss = 2.4189, ce loss = 0.4506, contrastive loss = 1.2114, lr = 1.7324562383303276e-05
average data time = 0.0292s, average running time = 1.4672s
epoch 109 iter 31828: eval loss = 1.3591,  ccr = 0.7540,  cwr = 0.6514,  ted = 15377.0000,  ned = 2767.6510,  ted/w = 1.0937, 
Better model found at epoch 109, iter 31828 with accuracy value: 0.6514.
epoch 110 iter 32120: loss = 2.3253, smooth loss = 2.3957, ce loss = 0.5151, contrastive loss = 1.2950, lr = 1.4336472853254332e-05
average data time = 0.0292s, average running time = 1.4681s
epoch 110 iter 32120: eval loss = 1.3581,  ccr = 0.7552,  cwr = 0.6510,  ted = 15338.0000,  ned = 2772.5910,  ted/w = 1.0910, 
epoch 111 iter 32412: loss = 2.3192, smooth loss = 2.3830, ce loss = 0.5259, contrastive loss = 1.2675, lr = 1.1626426536487078e-05
average data time = 0.0292s, average running time = 1.4689s
epoch 111 iter 32412: eval loss = 1.3579,  ccr = 0.7551,  cwr = 0.6501,  ted = 15318.0000,  ned = 2782.9773,  ted/w = 1.0896, 
epoch 112 iter 32704: loss = 2.6631, smooth loss = 2.3923, ce loss = 0.6838, contrastive loss = 1.2955, lr = 9.196377226417202e-06
average data time = 0.0292s, average running time = 1.4696s
epoch 112 iter 32704: eval loss = 1.3626,  ccr = 0.7547,  cwr = 0.6508,  ted = 15323.0000,  ned = 2773.6475,  ted/w = 1.0899, 
epoch 113 iter 32996: loss = 2.3590, smooth loss = 2.3914, ce loss = 0.5579, contrastive loss = 1.2433, lr = 7.04807685411396e-06
average data time = 0.0292s, average running time = 1.4703s
epoch 113 iter 32996: eval loss = 1.3623,  ccr = 0.7545,  cwr = 0.6509,  ted = 15385.0000,  ned = 2783.3337,  ted/w = 1.0943, 
epoch 114 iter 33288: loss = 2.6030, smooth loss = 2.3744, ce loss = 0.6547, contrastive loss = 1.2936, lr = 5.183074225255083e-06
average data time = 0.0291s, average running time = 1.4710s
epoch 114 iter 33288: eval loss = 1.3619,  ccr = 0.7543,  cwr = 0.6493,  ted = 15404.0000,  ned = 2796.9681,  ted/w = 1.0957, 
epoch 115 iter 33580: loss = 2.5055, smooth loss = 2.3742, ce loss = 0.6160, contrastive loss = 1.2735, lr = 3.6027139035234053e-06
average data time = 0.0291s, average running time = 1.4718s
epoch 115 iter 33580: eval loss = 1.3676,  ccr = 0.7546,  cwr = 0.6501,  ted = 15361.0000,  ned = 2788.7447,  ted/w = 1.0926, 
epoch 116 iter 33872: loss = 2.4178, smooth loss = 2.3687, ce loss = 0.5755, contrastive loss = 1.2668, lr = 2.308135241251002e-06
average data time = 0.0291s, average running time = 1.4725s
epoch 116 iter 33872: eval loss = 1.3616,  ccr = 0.7547,  cwr = 0.6495,  ted = 15317.0000,  ned = 2776.9463,  ted/w = 1.0895, 
epoch 117 iter 34164: loss = 2.2075, smooth loss = 2.3924, ce loss = 0.4931, contrastive loss = 1.2213, lr = 1.300271558009043e-06
average data time = 0.0291s, average running time = 1.4732s
epoch 117 iter 34164: eval loss = 1.3605,  ccr = 0.7549,  cwr = 0.6503,  ted = 15341.0000,  ned = 2782.8754,  ted/w = 1.0912, 
epoch 118 iter 34456: loss = 2.2380, smooth loss = 2.3297, ce loss = 0.5039, contrastive loss = 1.2302, lr = 5.79849467736198e-07
average data time = 0.0291s, average running time = 1.4738s
epoch 118 iter 34456: eval loss = 1.3630,  ccr = 0.7547,  cwr = 0.6493,  ted = 15354.0000,  ned = 2786.4332,  ted/w = 1.0921, 
epoch 119 iter 34748: loss = 2.6336, smooth loss = 2.3757, ce loss = 0.6708, contrastive loss = 1.2919, lr = 1.4738835489012343e-07
average data time = 0.0290s, average running time = 1.4745s
epoch 119 iter 34748: eval loss = 1.3628,  ccr = 0.7546,  cwr = 0.6493,  ted = 15359.0000,  ned = 2787.8080,  ted/w = 1.0925, 
