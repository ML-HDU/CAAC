You have chosen to seed training. This will slow down your training!
Construct dataset.
112471 training items found.
14059 valid items found.
Construct model.
Model(
  (backbone): SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(1, 4), stride=(1, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        dim=96, input_resolution=(32, 64), depth=2
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=96, window_size=(2, 8), num_heads=3
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=96, window_size=(2, 8), num_heads=3
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          input_resolution=(32, 64), dim=96
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        dim=192, input_resolution=(16, 32), depth=2
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=192, window_size=(2, 8), num_heads=6
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=192, window_size=(2, 8), num_heads=6
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          input_resolution=(16, 32), dim=192
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        dim=384, input_resolution=(8, 16), depth=18
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
  )
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (decoder): PositionAttention(
    (k_encoder): Sequential(
      (0): Sequential(
        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (2): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (k_decoder): Sequential(
      (0): Sequential(
        (0): Upsample(scale_factor=2.0, mode=nearest)
        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Upsample(scale_factor=2.0, mode=nearest)
        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace=True)
      )
      (2): Sequential(
        (0): Upsample(size=(4, 32), mode=nearest)
        (1): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace=True)
      )
    )
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0, inplace=False)
    )
    (project): Linear(in_features=512, out_features=512, bias=True)
  )
  (cls): Linear(in_features=512, out_features=7935, bias=True)
)
The parameters size of model is 41.312897 MB
Construct learner.
Use 4 GPUs.
Start training.
epoch 1 iter 292: loss = 4.9659, smooth loss = 5.1418, ce loss = 4.9659, contrastive loss = 0.0000, lr = 0.00022400000000000002
epoch 2 iter 584: loss = 4.7412, smooth loss = 4.8918, ce loss = 4.7412, contrastive loss = 0.0000, lr = 0.0006079999999999999
epoch 3 iter 876: loss = 4.4162, smooth loss = 4.6311, ce loss = 4.4162, contrastive loss = 0.0000, lr = 0.0008
epoch 4 iter 1168: loss = 4.2007, smooth loss = 4.1932, ce loss = 4.2007, contrastive loss = 0.0000, lr = 0.0007998558116451099
epoch 5 iter 1460: loss = 3.7239, smooth loss = 3.7837, ce loss = 3.7239, contrastive loss = 0.0000, lr = 0.0007994233505322638
epoch 6 iter 1752: loss = 3.3336, smooth loss = 3.4458, ce loss = 3.3336, contrastive loss = 0.0000, lr = 0.000798702928441991
epoch 7 iter 2044: loss = 2.8447, smooth loss = 3.1827, ce loss = 2.8447, contrastive loss = 0.0000, lr = 0.000797695064758749
epoch 8 iter 2336: loss = 2.8289, smooth loss = 2.9796, ce loss = 2.8289, contrastive loss = 0.0000, lr = 0.0007964004860964767
epoch 9 iter 2628: loss = 2.8794, smooth loss = 2.8439, ce loss = 2.8794, contrastive loss = 0.0000, lr = 0.0007948201257747449
epoch 10 iter 2920: loss = 2.5825, smooth loss = 2.6905, ce loss = 2.5825, contrastive loss = 0.0000, lr = 0.000792955123145886
epoch 11 iter 3212: loss = 2.5893, smooth loss = 2.5986, ce loss = 2.5893, contrastive loss = 0.0000, lr = 0.0007908068227735828
epoch 12 iter 3504: loss = 2.5743, smooth loss = 2.5377, ce loss = 2.5743, contrastive loss = 0.0000, lr = 0.000788376773463513
epoch 13 iter 3796: loss = 2.3174, smooth loss = 2.4394, ce loss = 2.3174, contrastive loss = 0.0000, lr = 0.0007856667271467458
epoch 14 iter 4088: loss = 2.4155, smooth loss = 2.3813, ce loss = 2.4155, contrastive loss = 0.0000, lr = 0.0007826786376166968
epoch 15 iter 4380: loss = 2.1557, smooth loss = 2.3163, ce loss = 2.1557, contrastive loss = 0.0000, lr = 0.0007794146591205511
epoch 16 iter 4672: loss = 2.1820, smooth loss = 2.2592, ce loss = 2.1820, contrastive loss = 0.0000, lr = 0.0007758771448061701
epoch 17 iter 4964: loss = 2.1478, smooth loss = 2.2122, ce loss = 2.1478, contrastive loss = 0.0000, lr = 0.0007720686450256023
epoch 18 iter 5256: loss = 2.0068, smooth loss = 2.1771, ce loss = 2.0068, contrastive loss = 0.0000, lr = 0.0007679919054964199
epoch 19 iter 5548: loss = 2.0359, smooth loss = 2.1372, ce loss = 2.0359, contrastive loss = 0.0000, lr = 0.0007636498653222099
epoch 20 iter 5840: loss = 2.0538, smooth loss = 2.0969, ce loss = 2.0538, contrastive loss = 0.0000, lr = 0.0007590456548736415
Save model train-seed-42-FuDan-Scene-32-256-bs-384-lr-0.0008-d_model-512-epoch-120-decay-cos-grad-clip-20-AdamW-wd-0.15-PA-decoder-max-len-40-sup_con-0.0-ce-2.0-temperature-0.15-warm_up-0.025_20_5840
epoch 21 iter 6132: loss = 2.3516, smooth loss = 2.0680, ce loss = 2.3516, contrastive loss = 0.0000, lr = 0.0007541825935316429
epoch 22 iter 6424: loss = 1.7203, smooth loss = 2.0278, ce loss = 1.7203, contrastive loss = 0.0000, lr = 0.0007490641872943116
epoch 23 iter 6716: loss = 1.8888, smooth loss = 1.9947, ce loss = 1.8888, contrastive loss = 0.0000, lr = 0.0007436941262492827
epoch 24 iter 7008: loss = 2.0249, smooth loss = 1.9598, ce loss = 2.0249, contrastive loss = 0.0000, lr = 0.0007380762819133811
epoch 25 iter 7300: loss = 1.8260, smooth loss = 1.9413, ce loss = 1.8260, contrastive loss = 0.0000, lr = 0.0007322147044414715
epoch 26 iter 7592: loss = 1.7807, smooth loss = 1.8928, ce loss = 1.7807, contrastive loss = 0.0000, lr = 0.0007261136197065211
epoch 27 iter 7884: loss = 1.5408, smooth loss = 1.8922, ce loss = 1.5408, contrastive loss = 0.0000, lr = 0.0007197774262529791
epoch 28 iter 8176: loss = 1.8830, smooth loss = 1.8693, ce loss = 1.8830, contrastive loss = 0.0000, lr = 0.0007132106921256691
epoch 29 iter 8468: loss = 1.5311, smooth loss = 1.7989, ce loss = 1.5311, contrastive loss = 0.0000, lr = 0.0007064181515764822
epoch 30 iter 8760: loss = 1.7634, smooth loss = 1.8170, ce loss = 1.7634, contrastive loss = 0.0000, lr = 0.0006994047016512434
epoch 31 iter 9052: loss = 1.6499, smooth loss = 1.7849, ce loss = 1.6499, contrastive loss = 0.0000, lr = 0.0006921753986592118
epoch 32 iter 9344: loss = 1.5967, smooth loss = 1.7723, ce loss = 1.5967, contrastive loss = 0.0000, lr = 0.0006847354545277624
epoch 33 iter 9636: loss = 1.7232, smooth loss = 1.7556, ce loss = 1.7232, contrastive loss = 0.0000, lr = 0.0006770902330448742
epoch 34 iter 9928: loss = 1.5410, smooth loss = 1.7218, ce loss = 1.5410, contrastive loss = 0.0000, lr = 0.0006692452459921362
epoch 35 iter 10220: loss = 1.7097, smooth loss = 1.6936, ce loss = 1.7097, contrastive loss = 0.0000, lr = 0.000661206149171058
epoch 36 iter 10512: loss = 1.6269, smooth loss = 1.6824, ce loss = 1.6269, contrastive loss = 0.0000, lr = 0.0006529787383255499
epoch 37 iter 10804: loss = 1.4896, smooth loss = 1.6859, ce loss = 1.4896, contrastive loss = 0.0000, lr = 0.0006445689449635119
epoch 38 iter 11096: loss = 1.5958, smooth loss = 1.6253, ce loss = 1.5958, contrastive loss = 0.0000, lr = 0.0006359828320805452
epoch 39 iter 11388: loss = 1.5581, smooth loss = 1.6452, ce loss = 1.5581, contrastive loss = 0.0000, lr = 0.0006272265897888675
epoch 40 iter 11680: loss = 1.5977, smooth loss = 1.6255, ce loss = 1.5977, contrastive loss = 0.0000, lr = 0.0006183065308545855
Save model train-seed-42-FuDan-Scene-32-256-bs-384-lr-0.0008-d_model-512-epoch-120-decay-cos-grad-clip-20-AdamW-wd-0.15-PA-decoder-max-len-40-sup_con-0.0-ce-2.0-temperature-0.15-warm_up-0.025_40_11680
epoch 41 iter 11972: loss = 1.4312, smooth loss = 1.6052, ce loss = 1.4312, contrastive loss = 0.0000, lr = 0.0006092290861465388
epoch 42 iter 12264: loss = 1.4701, smooth loss = 1.6023, ce loss = 1.4701, contrastive loss = 0.0000, lr = 0.0006000008
epoch 43 iter 12556: loss = 1.6459, smooth loss = 1.5739, ce loss = 1.6459, contrastive loss = 0.0000, lr = 0.0005906283254985711
epoch 44 iter 12848: loss = 1.5429, smooth loss = 1.5610, ce loss = 1.5429, contrastive loss = 0.0000, lr = 0.0005811184196776785
epoch 45 iter 13140: loss = 1.4254, smooth loss = 1.5397, ce loss = 1.4254, contrastive loss = 0.0000, lr = 0.0005714779386531235
epoch 46 iter 13432: loss = 1.3554, smooth loss = 1.5117, ce loss = 1.3554, contrastive loss = 0.0000, lr = 0.0005617138326782039
epoch 47 iter 13724: loss = 1.3787, smooth loss = 1.4841, ce loss = 1.3787, contrastive loss = 0.0000, lr = 0.0005518331411329647
epoch 48 iter 14016: loss = 1.4542, smooth loss = 1.4778, ce loss = 1.4542, contrastive loss = 0.0000, lr = 0.000541842987449195
epoch 49 iter 14308: loss = 1.3166, smooth loss = 1.4633, ce loss = 1.3166, contrastive loss = 0.0000, lr = 0.0005317505739748281
epoch 50 iter 14600: loss = 1.3332, smooth loss = 1.4590, ce loss = 1.3332, contrastive loss = 0.0000, lr = 0.0005215631767814466
epoch 51 iter 14892: loss = 1.4472, smooth loss = 1.4648, ce loss = 1.4472, contrastive loss = 0.0000, lr = 0.0005112881404186389
epoch 52 iter 15184: loss = 1.3169, smooth loss = 1.4158, ce loss = 1.3169, contrastive loss = 0.0000, lr = 0.0005009328726189833
epoch 53 iter 15476: loss = 1.3481, smooth loss = 1.4253, ce loss = 1.3481, contrastive loss = 0.0000, lr = 0.0004905048389574851
epoch 54 iter 15768: loss = 1.2317, smooth loss = 1.4149, ce loss = 1.2317, contrastive loss = 0.0000, lr = 0.00048001155746930777
epoch 55 iter 16060: loss = 1.4308, smooth loss = 1.3735, ce loss = 1.4308, contrastive loss = 0.0000, lr = 0.00046946059322968797
epoch 56 iter 16352: loss = 1.3308, smooth loss = 1.3803, ce loss = 1.3308, contrastive loss = 0.0000, lr = 0.00045885955289993313
epoch 57 iter 16644: loss = 1.4221, smooth loss = 1.3590, ce loss = 1.4221, contrastive loss = 0.0000, lr = 0.0004482160792434408
epoch 58 iter 16936: loss = 1.2132, smooth loss = 1.3424, ce loss = 1.2132, contrastive loss = 0.0000, lr = 0.0004375378456156887
epoch 59 iter 17228: loss = 1.2884, smooth loss = 1.3334, ce loss = 1.2884, contrastive loss = 0.0000, lr = 0.00042683255043216993
epoch 60 iter 17520: loss = 1.3504, smooth loss = 1.3089, ce loss = 1.3504, contrastive loss = 0.0000, lr = 0.0004161079116182619
Save model train-seed-42-FuDan-Scene-32-256-bs-384-lr-0.0008-d_model-512-epoch-120-decay-cos-grad-clip-20-AdamW-wd-0.15-PA-decoder-max-len-40-sup_con-0.0-ce-2.0-temperature-0.15-warm_up-0.025_60_17520
epoch 61 iter 17812: loss = 1.3317, smooth loss = 1.3104, ce loss = 1.3317, contrastive loss = 0.0000, lr = 0.0004053716610450289
epoch 62 iter 18104: loss = 1.1893, smooth loss = 1.2797, ce loss = 1.1893, contrastive loss = 0.0000, lr = 0.0003946315389549712
epoch 63 iter 18396: loss = 1.2861, smooth loss = 1.2756, ce loss = 1.2861, contrastive loss = 0.0000, lr = 0.00038389528838173823
epoch 64 iter 18688: loss = 1.2447, smooth loss = 1.2522, ce loss = 1.2447, contrastive loss = 0.0000, lr = 0.00037317064956783006
epoch 65 iter 18980: loss = 1.1282, smooth loss = 1.2408, ce loss = 1.1282, contrastive loss = 0.0000, lr = 0.0003624653543843114
epoch 66 iter 19272: loss = 0.8726, smooth loss = 1.2221, ce loss = 0.8726, contrastive loss = 0.0000, lr = 0.00035178712075655926
epoch 67 iter 19564: loss = 1.2137, smooth loss = 1.2014, ce loss = 1.2137, contrastive loss = 0.0000, lr = 0.0003411436471000669
epoch 68 iter 19856: loss = 1.3674, smooth loss = 1.1872, ce loss = 1.3674, contrastive loss = 0.0000, lr = 0.0003305426067703122
epoch 69 iter 20148: loss = 1.1057, smooth loss = 1.1803, ce loss = 1.1057, contrastive loss = 0.0000, lr = 0.00031999164253069233
average data time = 0.0194s, average running time = 0.7727s
epoch 69 iter 20148: eval loss = 1.3965,  ccr = 0.7061,  cwr = 0.5863,  ted = 19657.0000,  ned = 3397.4532,  ted/w = 1.3982, 
Better model found at epoch 69, iter 20148 with accuracy value: 0.5863.
epoch 70 iter 20440: loss = 1.1229, smooth loss = 1.1651, ce loss = 1.1229, contrastive loss = 0.0000, lr = 0.0003094983610425151
average data time = 0.0194s, average running time = 0.7750s
epoch 70 iter 20440: eval loss = 1.3893,  ccr = 0.7109,  cwr = 0.5924,  ted = 18849.0000,  ned = 3344.5259,  ted/w = 1.3407, 
Better model found at epoch 70, iter 20440 with accuracy value: 0.5924.
epoch 71 iter 20732: loss = 1.1677, smooth loss = 1.1510, ce loss = 1.1677, contrastive loss = 0.0000, lr = 0.0002990703273810167
average data time = 0.0194s, average running time = 0.7771s
epoch 71 iter 20732: eval loss = 1.3704,  ccr = 0.7092,  cwr = 0.5866,  ted = 19308.0000,  ned = 3420.4700,  ted/w = 1.3734, 
epoch 72 iter 21024: loss = 0.9821, smooth loss = 1.1542, ce loss = 0.9821, contrastive loss = 0.0000, lr = 0.0002887150595813612
average data time = 0.0193s, average running time = 0.7791s
epoch 72 iter 21024: eval loss = 1.3736,  ccr = 0.7096,  cwr = 0.5897,  ted = 18884.0000,  ned = 3322.7679,  ted/w = 1.3432, 
epoch 73 iter 21316: loss = 0.9543, smooth loss = 1.1394, ce loss = 0.9543, contrastive loss = 0.0000, lr = 0.0002784400232185534
average data time = 0.0193s, average running time = 0.7809s
epoch 73 iter 21316: eval loss = 1.3812,  ccr = 0.7099,  cwr = 0.5883,  ted = 19544.0000,  ned = 3431.4283,  ted/w = 1.3901, 
epoch 74 iter 21608: loss = 1.1232, smooth loss = 1.1199, ce loss = 1.1232, contrastive loss = 0.0000, lr = 0.0002682526260251721
average data time = 0.0193s, average running time = 0.7827s
epoch 74 iter 21608: eval loss = 1.3565,  ccr = 0.7098,  cwr = 0.5913,  ted = 19194.0000,  ned = 3360.7649,  ted/w = 1.3652, 
epoch 75 iter 21900: loss = 1.0995, smooth loss = 1.1222, ce loss = 1.0995, contrastive loss = 0.0000, lr = 0.00025816021255080504
average data time = 0.0193s, average running time = 0.7845s
epoch 75 iter 21900: eval loss = 1.3478,  ccr = 0.7142,  cwr = 0.5947,  ted = 18543.0000,  ned = 3314.0631,  ted/w = 1.3189, 
Better model found at epoch 75, iter 21900 with accuracy value: 0.5947.
epoch 76 iter 22192: loss = 1.0387, smooth loss = 1.0764, ce loss = 1.0387, contrastive loss = 0.0000, lr = 0.00024817005886703536
average data time = 0.0193s, average running time = 0.7865s
epoch 76 iter 22192: eval loss = 1.3692,  ccr = 0.7163,  cwr = 0.5949,  ted = 18534.0000,  ned = 3325.3895,  ted/w = 1.3183, 
Better model found at epoch 76, iter 22192 with accuracy value: 0.5949.
epoch 77 iter 22484: loss = 1.0179, smooth loss = 1.0776, ce loss = 1.0179, contrastive loss = 0.0000, lr = 0.0002382893673217962
average data time = 0.0193s, average running time = 0.7882s
epoch 77 iter 22484: eval loss = 1.3497,  ccr = 0.7148,  cwr = 0.5978,  ted = 18540.0000,  ned = 3293.9947,  ted/w = 1.3187, 
Better model found at epoch 77, iter 22484 with accuracy value: 0.5978.
epoch 78 iter 22776: loss = 0.8942, smooth loss = 1.0634, ce loss = 0.8942, contrastive loss = 0.0000, lr = 0.00022852526134687652
average data time = 0.0193s, average running time = 0.7899s
epoch 78 iter 22776: eval loss = 1.3747,  ccr = 0.7181,  cwr = 0.5977,  ted = 18436.0000,  ned = 3293.6554,  ted/w = 1.3113, 
epoch 79 iter 23068: loss = 1.0155, smooth loss = 1.0716, ce loss = 1.0155, contrastive loss = 0.0000, lr = 0.00021888478032232176
average data time = 0.0192s, average running time = 0.7915s
epoch 79 iter 23068: eval loss = 1.3475,  ccr = 0.7168,  cwr = 0.6016,  ted = 18302.0000,  ned = 3231.4819,  ted/w = 1.3018, 
Better model found at epoch 79, iter 23068 with accuracy value: 0.6016.
epoch 80 iter 23360: loss = 1.0503, smooth loss = 1.0477, ce loss = 1.0503, contrastive loss = 0.0000, lr = 0.0002093748745014289
average data time = 0.0192s, average running time = 0.7932s
epoch 80 iter 23360: eval loss = 1.3429,  ccr = 0.7192,  cwr = 0.6005,  ted = 18510.0000,  ned = 3243.9174,  ted/w = 1.3166, 
Save model train-seed-42-FuDan-Scene-32-256-bs-384-lr-0.0008-d_model-512-epoch-120-decay-cos-grad-clip-20-AdamW-wd-0.15-PA-decoder-max-len-40-sup_con-0.0-ce-2.0-temperature-0.15-warm_up-0.025_80_23360
epoch 81 iter 23652: loss = 0.9678, smooth loss = 1.0305, ce loss = 0.9678, contrastive loss = 0.0000, lr = 0.0002000024000000001
average data time = 0.0192s, average running time = 0.7948s
epoch 81 iter 23652: eval loss = 1.3642,  ccr = 0.7188,  cwr = 0.6013,  ted = 18126.0000,  ned = 3205.5187,  ted/w = 1.2893, 
epoch 82 iter 23944: loss = 1.0163, smooth loss = 1.0449, ce loss = 1.0163, contrastive loss = 0.0000, lr = 0.00019077411385346127
average data time = 0.0192s, average running time = 0.7963s
epoch 82 iter 23944: eval loss = 1.3438,  ccr = 0.7184,  cwr = 0.5996,  ted = 18028.0000,  ned = 3212.0343,  ted/w = 1.2823, 
epoch 83 iter 24236: loss = 1.0340, smooth loss = 1.0136, ce loss = 1.0340, contrastive loss = 0.0000, lr = 0.00018169666914541447
average data time = 0.0192s, average running time = 0.7977s
epoch 83 iter 24236: eval loss = 1.3310,  ccr = 0.7224,  cwr = 0.6054,  ted = 18016.0000,  ned = 3204.9033,  ted/w = 1.2815, 
Better model found at epoch 83, iter 24236 with accuracy value: 0.6054.
epoch 84 iter 24528: loss = 0.8918, smooth loss = 0.9933, ce loss = 0.8918, contrastive loss = 0.0000, lr = 0.0001727766102111325
average data time = 0.0192s, average running time = 0.7992s
epoch 84 iter 24528: eval loss = 1.3572,  ccr = 0.7195,  cwr = 0.6022,  ted = 18399.0000,  ned = 3258.6416,  ted/w = 1.3087, 
epoch 85 iter 24820: loss = 0.9752, smooth loss = 0.9935, ce loss = 0.9752, contrastive loss = 0.0000, lr = 0.000164020367919455
average data time = 0.0191s, average running time = 0.8006s
epoch 85 iter 24820: eval loss = 1.3375,  ccr = 0.7229,  cwr = 0.6040,  ted = 17894.0000,  ned = 3212.7722,  ted/w = 1.2728, 
epoch 86 iter 25112: loss = 0.9125, smooth loss = 0.9772, ce loss = 0.9125, contrastive loss = 0.0000, lr = 0.00015543425503648805
average data time = 0.0191s, average running time = 0.8020s
epoch 86 iter 25112: eval loss = 1.3378,  ccr = 0.7254,  cwr = 0.6091,  ted = 17555.0000,  ned = 3163.9072,  ted/w = 1.2487, 
Better model found at epoch 86, iter 25112 with accuracy value: 0.6091.
epoch 87 iter 25404: loss = 1.0410, smooth loss = 0.9680, ce loss = 1.0410, contrastive loss = 0.0000, lr = 0.0001470244616744501
average data time = 0.0191s, average running time = 0.8034s
epoch 87 iter 25404: eval loss = 1.3634,  ccr = 0.7235,  cwr = 0.6092,  ted = 17527.0000,  ned = 3168.3143,  ted/w = 1.2467, 
Better model found at epoch 87, iter 25404 with accuracy value: 0.6092.
epoch 88 iter 25696: loss = 0.9638, smooth loss = 0.9468, ce loss = 0.9638, contrastive loss = 0.0000, lr = 0.00013879705082894204
average data time = 0.0191s, average running time = 0.8048s
epoch 88 iter 25696: eval loss = 1.3402,  ccr = 0.7278,  cwr = 0.6101,  ted = 17787.0000,  ned = 3159.9116,  ted/w = 1.2652, 
Better model found at epoch 88, iter 25696 with accuracy value: 0.6101.
epoch 89 iter 25988: loss = 0.8941, smooth loss = 0.9586, ce loss = 0.8941, contrastive loss = 0.0000, lr = 0.00013075795400786374
average data time = 0.0191s, average running time = 0.8061s
epoch 89 iter 25988: eval loss = 1.3233,  ccr = 0.7276,  cwr = 0.6117,  ted = 17529.0000,  ned = 3135.9558,  ted/w = 1.2468, 
Better model found at epoch 89, iter 25988 with accuracy value: 0.6117.
epoch 90 iter 26280: loss = 0.8594, smooth loss = 0.9424, ce loss = 0.8594, contrastive loss = 0.0000, lr = 0.00012291296695512586
average data time = 0.0191s, average running time = 0.8074s
epoch 90 iter 26280: eval loss = 1.3269,  ccr = 0.7277,  cwr = 0.6091,  ted = 17573.0000,  ned = 3148.3791,  ted/w = 1.2499, 
epoch 91 iter 26572: loss = 0.8049, smooth loss = 0.9146, ce loss = 0.8049, contrastive loss = 0.0000, lr = 0.00011526774547223771
average data time = 0.0191s, average running time = 0.8086s
epoch 91 iter 26572: eval loss = 1.3190,  ccr = 0.7302,  cwr = 0.6108,  ted = 17535.0000,  ned = 3164.9494,  ted/w = 1.2472, 
epoch 92 iter 26864: loss = 0.8179, smooth loss = 0.9299, ce loss = 0.8179, contrastive loss = 0.0000, lr = 0.00010782780134078822
average data time = 0.0191s, average running time = 0.8098s
epoch 92 iter 26864: eval loss = 1.3166,  ccr = 0.7288,  cwr = 0.6118,  ted = 17645.0000,  ned = 3151.6906,  ted/w = 1.2551, 
Better model found at epoch 92, iter 26864 with accuracy value: 0.6118.
epoch 93 iter 27156: loss = 0.9178, smooth loss = 0.9163, ce loss = 0.9178, contrastive loss = 0.0000, lr = 0.00010059849834875659
average data time = 0.0190s, average running time = 0.8110s
epoch 93 iter 27156: eval loss = 1.3226,  ccr = 0.7317,  cwr = 0.6156,  ted = 17459.0000,  ned = 3107.7366,  ted/w = 1.2418, 
Better model found at epoch 93, iter 27156 with accuracy value: 0.6156.
epoch 94 iter 27448: loss = 0.8885, smooth loss = 0.8872, ce loss = 0.8885, contrastive loss = 0.0000, lr = 9.358504842351783e-05
average data time = 0.0190s, average running time = 0.8122s
epoch 94 iter 27448: eval loss = 1.3423,  ccr = 0.7306,  cwr = 0.6177,  ted = 17057.0000,  ned = 3086.6940,  ted/w = 1.2132, 
Better model found at epoch 94, iter 27448 with accuracy value: 0.6177.
epoch 95 iter 27740: loss = 1.0130, smooth loss = 0.8993, ce loss = 1.0130, contrastive loss = 0.0000, lr = 8.679250787433099e-05
average data time = 0.0190s, average running time = 0.8135s
epoch 95 iter 27740: eval loss = 1.3293,  ccr = 0.7295,  cwr = 0.6139,  ted = 17174.0000,  ned = 3066.7823,  ted/w = 1.2216, 
epoch 96 iter 28032: loss = 0.9936, smooth loss = 0.8799, ce loss = 0.9936, contrastive loss = 0.0000, lr = 8.022577374702106e-05
average data time = 0.0190s, average running time = 0.8145s
epoch 96 iter 28032: eval loss = 1.3201,  ccr = 0.7327,  cwr = 0.6175,  ted = 17058.0000,  ned = 3077.3051,  ted/w = 1.2133, 
epoch 97 iter 28324: loss = 0.9875, smooth loss = 0.8722, ce loss = 0.9875, contrastive loss = 0.0000, lr = 7.388958029347893e-05
average data time = 0.0190s, average running time = 0.8155s
epoch 97 iter 28324: eval loss = 1.3293,  ccr = 0.7331,  cwr = 0.6192,  ted = 16984.0000,  ned = 3049.6857,  ted/w = 1.2081, 
Better model found at epoch 97, iter 28324 with accuracy value: 0.6192.
epoch 98 iter 28616: loss = 0.8625, smooth loss = 0.8769, ce loss = 0.8625, contrastive loss = 0.0000, lr = 6.778849555852853e-05
average data time = 0.0190s, average running time = 0.8166s
epoch 98 iter 28616: eval loss = 1.3198,  ccr = 0.7330,  cwr = 0.6171,  ted = 17214.0000,  ned = 3061.5237,  ted/w = 1.2244, 
epoch 99 iter 28908: loss = 0.8686, smooth loss = 0.8464, ce loss = 0.8686, contrastive loss = 0.0000, lr = 6.192691808661902e-05
average data time = 0.0190s, average running time = 0.8176s
epoch 99 iter 28908: eval loss = 1.3175,  ccr = 0.7336,  cwr = 0.6173,  ted = 17174.0000,  ned = 3069.5772,  ted/w = 1.2216, 
epoch 100 iter 29200: loss = 0.7974, smooth loss = 0.8521, ce loss = 0.7974, contrastive loss = 0.0000, lr = 5.630907375071737e-05
average data time = 0.0190s, average running time = 0.8186s
epoch 100 iter 29200: eval loss = 1.3318,  ccr = 0.7320,  cwr = 0.6189,  ted = 16934.0000,  ned = 3044.8613,  ted/w = 1.2045, 
Save model train-seed-42-FuDan-Scene-32-256-bs-384-lr-0.0008-d_model-512-epoch-120-decay-cos-grad-clip-20-AdamW-wd-0.15-PA-decoder-max-len-40-sup_con-0.0-ce-2.0-temperature-0.15-warm_up-0.025_100_29200
epoch 101 iter 29492: loss = 0.7495, smooth loss = 0.8387, ce loss = 0.7495, contrastive loss = 0.0000, lr = 5.093901270568848e-05
average data time = 0.0190s, average running time = 0.8197s
epoch 101 iter 29492: eval loss = 1.3240,  ccr = 0.7338,  cwr = 0.6209,  ted = 16808.0000,  ned = 3019.3967,  ted/w = 1.1955, 
Better model found at epoch 101, iter 29492 with accuracy value: 0.6209.
epoch 102 iter 29784: loss = 1.0049, smooth loss = 0.8192, ce loss = 1.0049, contrastive loss = 0.0000, lr = 4.582060646835713e-05
average data time = 0.0190s, average running time = 0.8207s
epoch 102 iter 29784: eval loss = 1.3334,  ccr = 0.7339,  cwr = 0.6202,  ted = 16983.0000,  ned = 3037.5028,  ted/w = 1.2080, 
epoch 103 iter 30076: loss = 0.7683, smooth loss = 0.8282, ce loss = 0.7683, contrastive loss = 0.0000, lr = 4.09575451263587e-05
average data time = 0.0190s, average running time = 0.8216s
epoch 103 iter 30076: eval loss = 1.3225,  ccr = 0.7361,  cwr = 0.6209,  ted = 16826.0000,  ned = 3025.0085,  ted/w = 1.1968, 
epoch 104 iter 30368: loss = 0.9328, smooth loss = 0.8271, ce loss = 0.9328, contrastive loss = 0.0000, lr = 3.635333467779016e-05
average data time = 0.0190s, average running time = 0.8225s
epoch 104 iter 30368: eval loss = 1.3273,  ccr = 0.7375,  cwr = 0.6233,  ted = 16800.0000,  ned = 3026.8761,  ted/w = 1.1950, 
Better model found at epoch 104, iter 30368 with accuracy value: 0.6233.
epoch 105 iter 30660: loss = 0.9466, smooth loss = 0.8321, ce loss = 0.9466, contrastive loss = 0.0000, lr = 3.201129450358016e-05
average data time = 0.0190s, average running time = 0.8235s
epoch 105 iter 30660: eval loss = 1.3174,  ccr = 0.7384,  cwr = 0.6246,  ted = 16785.0000,  ned = 3027.9959,  ted/w = 1.1939, 
Better model found at epoch 105, iter 30660 with accuracy value: 0.6246.
epoch 106 iter 30952: loss = 0.9054, smooth loss = 0.8037, ce loss = 0.9054, contrastive loss = 0.0000, lr = 2.7934554974397916e-05
average data time = 0.0189s, average running time = 0.8244s
epoch 106 iter 30952: eval loss = 1.3204,  ccr = 0.7368,  cwr = 0.6217,  ted = 16778.0000,  ned = 3017.7272,  ted/w = 1.1934, 
epoch 107 iter 31244: loss = 0.8136, smooth loss = 0.8008, ce loss = 0.8136, contrastive loss = 0.0000, lr = 2.412605519382993e-05
average data time = 0.0189s, average running time = 0.8254s
epoch 107 iter 31244: eval loss = 1.3148,  ccr = 0.7379,  cwr = 0.6241,  ted = 16596.0000,  ned = 2997.4131,  ted/w = 1.1805, 
epoch 108 iter 31536: loss = 0.7829, smooth loss = 0.7951, ce loss = 0.7829, contrastive loss = 0.0000, lr = 2.0588540879448922e-05
average data time = 0.0189s, average running time = 0.8262s
epoch 108 iter 31536: eval loss = 1.3142,  ccr = 0.7393,  cwr = 0.6247,  ted = 16678.0000,  ned = 3008.0151,  ted/w = 1.1863, 
Better model found at epoch 108, iter 31536 with accuracy value: 0.6247.
epoch 109 iter 31828: loss = 0.7008, smooth loss = 0.8010, ce loss = 0.7008, contrastive loss = 0.0000, lr = 1.7324562383303276e-05
average data time = 0.0189s, average running time = 0.8271s
epoch 109 iter 31828: eval loss = 1.3217,  ccr = 0.7386,  cwr = 0.6242,  ted = 16583.0000,  ned = 2981.3203,  ted/w = 1.1795, 
epoch 110 iter 32120: loss = 0.7677, smooth loss = 0.7929, ce loss = 0.7677, contrastive loss = 0.0000, lr = 1.4336472853254332e-05
average data time = 0.0189s, average running time = 0.8280s
epoch 110 iter 32120: eval loss = 1.3134,  ccr = 0.7397,  cwr = 0.6262,  ted = 16596.0000,  ned = 2997.7301,  ted/w = 1.1805, 
Better model found at epoch 110, iter 32120 with accuracy value: 0.6262.
epoch 111 iter 32412: loss = 0.7139, smooth loss = 0.8043, ce loss = 0.7139, contrastive loss = 0.0000, lr = 1.1626426536487078e-05
average data time = 0.0189s, average running time = 0.8288s
epoch 111 iter 32412: eval loss = 1.3137,  ccr = 0.7385,  cwr = 0.6237,  ted = 16659.0000,  ned = 2998.1438,  ted/w = 1.1849, 
epoch 112 iter 32704: loss = 0.7995, smooth loss = 0.7998, ce loss = 0.7995, contrastive loss = 0.0000, lr = 9.196377226417202e-06
average data time = 0.0189s, average running time = 0.8296s
epoch 112 iter 32704: eval loss = 1.3188,  ccr = 0.7400,  cwr = 0.6244,  ted = 16534.0000,  ned = 2997.4262,  ted/w = 1.1760, 
epoch 113 iter 32996: loss = 0.8376, smooth loss = 0.7971, ce loss = 0.8376, contrastive loss = 0.0000, lr = 7.04807685411396e-06
average data time = 0.0189s, average running time = 0.8303s
epoch 113 iter 32996: eval loss = 1.3117,  ccr = 0.7398,  cwr = 0.6254,  ted = 16631.0000,  ned = 2989.0008,  ted/w = 1.1829, 
epoch 114 iter 33288: loss = 0.8780, smooth loss = 0.7814, ce loss = 0.8780, contrastive loss = 0.0000, lr = 5.183074225255083e-06
average data time = 0.0189s, average running time = 0.8311s
epoch 114 iter 33288: eval loss = 1.3200,  ccr = 0.7397,  cwr = 0.6248,  ted = 16527.0000,  ned = 2984.8501,  ted/w = 1.1755, 
epoch 115 iter 33580: loss = 0.7940, smooth loss = 0.7731, ce loss = 0.7940, contrastive loss = 0.0000, lr = 3.6027139035234053e-06
average data time = 0.0189s, average running time = 0.8318s
epoch 115 iter 33580: eval loss = 1.3192,  ccr = 0.7395,  cwr = 0.6264,  ted = 16533.0000,  ned = 2980.7688,  ted/w = 1.1760, 
Better model found at epoch 115, iter 33580 with accuracy value: 0.6264.
epoch 116 iter 33872: loss = 0.8075, smooth loss = 0.7690, ce loss = 0.8075, contrastive loss = 0.0000, lr = 2.308135241251002e-06
average data time = 0.0189s, average running time = 0.8326s
epoch 116 iter 33872: eval loss = 1.3170,  ccr = 0.7400,  cwr = 0.6266,  ted = 16521.0000,  ned = 2975.6351,  ted/w = 1.1751, 
Better model found at epoch 116, iter 33872 with accuracy value: 0.6266.
epoch 117 iter 34164: loss = 0.8006, smooth loss = 0.7845, ce loss = 0.8006, contrastive loss = 0.0000, lr = 1.300271558009043e-06
average data time = 0.0189s, average running time = 0.8335s
epoch 117 iter 34164: eval loss = 1.3201,  ccr = 0.7403,  cwr = 0.6259,  ted = 16507.0000,  ned = 2976.7301,  ted/w = 1.1741, 
epoch 118 iter 34456: loss = 0.7123, smooth loss = 0.7740, ce loss = 0.7123, contrastive loss = 0.0000, lr = 5.79849467736198e-07
average data time = 0.0189s, average running time = 0.8341s
epoch 118 iter 34456: eval loss = 1.3220,  ccr = 0.7395,  cwr = 0.6263,  ted = 16541.0000,  ned = 2984.2882,  ted/w = 1.1765, 
epoch 119 iter 34748: loss = 0.7310, smooth loss = 0.7798, ce loss = 0.7310, contrastive loss = 0.0000, lr = 1.4738835489012343e-07
average data time = 0.0189s, average running time = 0.8348s
epoch 119 iter 34748: eval loss = 1.3175,  ccr = 0.7397,  cwr = 0.6256,  ted = 16533.0000,  ned = 2978.9969,  ted/w = 1.1760, 
