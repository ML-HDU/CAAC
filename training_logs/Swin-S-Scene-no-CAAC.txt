You have chosen to seed training. This will slow down your training!
Construct dataset.
509164 training items found.
63645 valid items found.
Construct model.
Model(
  (backbone): SwinTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 96, kernel_size=(1, 4), stride=(1, 4))
      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): BasicLayer(
        dim=96, input_resolution=(32, 64), depth=2
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=96, window_size=(2, 8), num_heads=3
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=96, window_size=(2, 8), num_heads=3
              (qkv): Linear(in_features=96, out_features=288, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=96, out_features=96, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=96, out_features=384, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=384, out_features=96, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          input_resolution=(32, 64), dim=96
          (reduction): Linear(in_features=384, out_features=192, bias=False)
          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): BasicLayer(
        dim=192, input_resolution=(16, 32), depth=2
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=192, window_size=(2, 8), num_heads=6
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=192, window_size=(2, 8), num_heads=6
              (qkv): Linear(in_features=192, out_features=576, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=192, out_features=192, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=192, out_features=768, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=768, out_features=192, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (downsample): PatchMerging(
          input_resolution=(16, 32), dim=192
          (reduction): Linear(in_features=768, out_features=384, bias=False)
          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): BasicLayer(
        dim=384, input_resolution=(8, 16), depth=18
        (blocks): ModuleList(
          (0): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SwinTransformerBlock(
            dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}
            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              dim=384, window_size=(2, 8), num_heads=12
              (qkv): Linear(in_features=384, out_features=1152, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=384, out_features=384, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU()
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
  )
  (conv): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (decoder): PositionAttention(
    (k_encoder): Sequential(
      (0): Sequential(
        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 2), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
      (2): Sequential(
        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU(inplace=True)
      )
    )
    (k_decoder): Sequential(
      (0): Sequential(
        (0): Upsample(scale_factor=2.0, mode=nearest)
        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace=True)
      )
      (1): Sequential(
        (0): Upsample(scale_factor=2.0, mode=nearest)
        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace=True)
      )
      (2): Sequential(
        (0): Upsample(size=(4, 32), mode=nearest)
        (1): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (3): ReLU(inplace=True)
      )
    )
    (pos_encoder): PositionalEncoding(
      (dropout): Dropout(p=0, inplace=False)
    )
    (project): Linear(in_features=512, out_features=512, bias=True)
  )
  (cls): Linear(in_features=512, out_features=7935, bias=True)
)
The parameters size of model is 41.312897 MB
Construct learner.
Use 4 GPUs.
Start training.
epoch 1 iter 1325: loss = 5.3301, smooth loss = 5.3538, ce loss = 5.3301, contrastive loss = 0.0000, lr = 0.00022400000000000002
epoch 2 iter 2650: loss = 5.1846, smooth loss = 5.0870, ce loss = 5.1846, contrastive loss = 0.0000, lr = 0.0006079999999999999
epoch 3 iter 3975: loss = 3.7332, smooth loss = 3.9711, ce loss = 3.7332, contrastive loss = 0.0000, lr = 0.0008
epoch 4 iter 5300: loss = 3.2472, smooth loss = 3.2691, ce loss = 3.2472, contrastive loss = 0.0000, lr = 0.0007998558116451099
epoch 5 iter 6625: loss = 2.9970, smooth loss = 2.9134, ce loss = 2.9970, contrastive loss = 0.0000, lr = 0.0007994233505322638
epoch 6 iter 7950: loss = 2.5471, smooth loss = 2.6845, ce loss = 2.5471, contrastive loss = 0.0000, lr = 0.000798702928441991
epoch 7 iter 9275: loss = 2.1827, smooth loss = 2.4786, ce loss = 2.1827, contrastive loss = 0.0000, lr = 0.000797695064758749
epoch 8 iter 10600: loss = 2.1878, smooth loss = 2.3661, ce loss = 2.1878, contrastive loss = 0.0000, lr = 0.0007964004860964767
epoch 9 iter 11925: loss = 2.1955, smooth loss = 2.2528, ce loss = 2.1955, contrastive loss = 0.0000, lr = 0.0007948201257747449
epoch 10 iter 13250: loss = 2.0431, smooth loss = 2.1603, ce loss = 2.0431, contrastive loss = 0.0000, lr = 0.000792955123145886
epoch 11 iter 14575: loss = 1.9921, smooth loss = 2.0791, ce loss = 1.9921, contrastive loss = 0.0000, lr = 0.0007908068227735828
epoch 12 iter 15900: loss = 1.9783, smooth loss = 2.0106, ce loss = 1.9783, contrastive loss = 0.0000, lr = 0.000788376773463513
epoch 13 iter 17225: loss = 1.8537, smooth loss = 1.9892, ce loss = 1.8537, contrastive loss = 0.0000, lr = 0.0007856667271467458
epoch 14 iter 18550: loss = 2.1280, smooth loss = 1.9400, ce loss = 2.1280, contrastive loss = 0.0000, lr = 0.0007826786376166968
epoch 15 iter 19875: loss = 1.8822, smooth loss = 1.8691, ce loss = 1.8822, contrastive loss = 0.0000, lr = 0.0007794146591205511
epoch 16 iter 21200: loss = 1.6786, smooth loss = 1.8390, ce loss = 1.6786, contrastive loss = 0.0000, lr = 0.0007758771448061701
epoch 17 iter 22525: loss = 1.4286, smooth loss = 1.8175, ce loss = 1.4286, contrastive loss = 0.0000, lr = 0.0007720686450256023
epoch 18 iter 23850: loss = 1.6416, smooth loss = 1.7611, ce loss = 1.6416, contrastive loss = 0.0000, lr = 0.0007679919054964199
epoch 19 iter 25175: loss = 1.7624, smooth loss = 1.7110, ce loss = 1.7624, contrastive loss = 0.0000, lr = 0.0007636498653222099
epoch 20 iter 26500: loss = 1.8703, smooth loss = 1.7143, ce loss = 1.8703, contrastive loss = 0.0000, lr = 0.0007590456548736415
epoch 21 iter 27825: loss = 1.6439, smooth loss = 1.6935, ce loss = 1.6439, contrastive loss = 0.0000, lr = 0.0007541825935316429
epoch 22 iter 29150: loss = 1.5768, smooth loss = 1.6675, ce loss = 1.5768, contrastive loss = 0.0000, lr = 0.0007490641872943116
epoch 23 iter 30475: loss = 1.5566, smooth loss = 1.6150, ce loss = 1.5566, contrastive loss = 0.0000, lr = 0.0007436941262492827
epoch 24 iter 31800: loss = 1.4756, smooth loss = 1.5966, ce loss = 1.4756, contrastive loss = 0.0000, lr = 0.0007380762819133811
epoch 25 iter 33125: loss = 1.7178, smooth loss = 1.5844, ce loss = 1.7178, contrastive loss = 0.0000, lr = 0.0007322147044414715
epoch 26 iter 34450: loss = 1.4850, smooth loss = 1.5703, ce loss = 1.4850, contrastive loss = 0.0000, lr = 0.0007261136197065211
epoch 27 iter 35775: loss = 1.3636, smooth loss = 1.5300, ce loss = 1.3636, contrastive loss = 0.0000, lr = 0.0007197774262529791
epoch 28 iter 37100: loss = 1.3247, smooth loss = 1.5025, ce loss = 1.3247, contrastive loss = 0.0000, lr = 0.0007132106921256691
epoch 29 iter 38425: loss = 1.2457, smooth loss = 1.5014, ce loss = 1.2457, contrastive loss = 0.0000, lr = 0.0007064181515764822
epoch 30 iter 39750: loss = 1.5795, smooth loss = 1.4690, ce loss = 1.5795, contrastive loss = 0.0000, lr = 0.0006994047016512434
Save model train-seed-42-FuDan-Scene-32-256-bs-384-lr-0.0008-d_model-512-epoch-120-decay-cos-grad-clip-20-AdamW-wd-0.01-PA-decoder-max-len-40-sup_con-0.0-ce-2.0-temperature-0.15-warm_up-0.025_30_40000
epoch 31 iter 41075: loss = 1.3791, smooth loss = 1.4479, ce loss = 1.3791, contrastive loss = 0.0000, lr = 0.0006921753986592118
epoch 32 iter 42400: loss = 1.5726, smooth loss = 1.4486, ce loss = 1.5726, contrastive loss = 0.0000, lr = 0.0006847354545277624
epoch 33 iter 43725: loss = 1.6543, smooth loss = 1.4129, ce loss = 1.6543, contrastive loss = 0.0000, lr = 0.0006770902330448742
epoch 34 iter 45050: loss = 1.3696, smooth loss = 1.4240, ce loss = 1.3696, contrastive loss = 0.0000, lr = 0.0006692452459921362
epoch 35 iter 46375: loss = 1.3082, smooth loss = 1.3944, ce loss = 1.3082, contrastive loss = 0.0000, lr = 0.000661206149171058
epoch 36 iter 47700: loss = 1.0915, smooth loss = 1.3523, ce loss = 1.0915, contrastive loss = 0.0000, lr = 0.0006529787383255499
epoch 37 iter 49025: loss = 1.4650, smooth loss = 1.3595, ce loss = 1.4650, contrastive loss = 0.0000, lr = 0.0006445689449635119
epoch 38 iter 50350: loss = 1.3837, smooth loss = 1.3346, ce loss = 1.3837, contrastive loss = 0.0000, lr = 0.0006359828320805452
epoch 39 iter 51675: loss = 1.3380, smooth loss = 1.3218, ce loss = 1.3380, contrastive loss = 0.0000, lr = 0.0006272265897888675
epoch 40 iter 53000: loss = 1.4940, smooth loss = 1.3082, ce loss = 1.4940, contrastive loss = 0.0000, lr = 0.0006183065308545855
epoch 41 iter 54325: loss = 1.1199, smooth loss = 1.2935, ce loss = 1.1199, contrastive loss = 0.0000, lr = 0.0006092290861465388
epoch 42 iter 55650: loss = 1.1659, smooth loss = 1.2790, ce loss = 1.1659, contrastive loss = 0.0000, lr = 0.0006000008
epoch 43 iter 56975: loss = 1.3652, smooth loss = 1.2486, ce loss = 1.3652, contrastive loss = 0.0000, lr = 0.0005906283254985711
epoch 44 iter 58300: loss = 1.1876, smooth loss = 1.2605, ce loss = 1.1876, contrastive loss = 0.0000, lr = 0.0005811184196776785
epoch 45 iter 59625: loss = 1.1915, smooth loss = 1.2147, ce loss = 1.1915, contrastive loss = 0.0000, lr = 0.0005714779386531235
epoch 46 iter 60950: loss = 1.3059, smooth loss = 1.2233, ce loss = 1.3059, contrastive loss = 0.0000, lr = 0.0005617138326782039
epoch 47 iter 62275: loss = 1.0498, smooth loss = 1.2137, ce loss = 1.0498, contrastive loss = 0.0000, lr = 0.0005518331411329647
epoch 48 iter 63600: loss = 1.2419, smooth loss = 1.1919, ce loss = 1.2419, contrastive loss = 0.0000, lr = 0.000541842987449195
epoch 49 iter 64925: loss = 1.2523, smooth loss = 1.1894, ce loss = 1.2523, contrastive loss = 0.0000, lr = 0.0005317505739748281
epoch 50 iter 66250: loss = 1.1071, smooth loss = 1.1620, ce loss = 1.1071, contrastive loss = 0.0000, lr = 0.0005215631767814466
epoch 51 iter 67575: loss = 1.2993, smooth loss = 1.1662, ce loss = 1.2993, contrastive loss = 0.0000, lr = 0.0005112881404186389
epoch 52 iter 68900: loss = 1.0096, smooth loss = 1.1294, ce loss = 1.0096, contrastive loss = 0.0000, lr = 0.0005009328726189833
epoch 53 iter 70225: loss = 1.0582, smooth loss = 1.1313, ce loss = 1.0582, contrastive loss = 0.0000, lr = 0.0004905048389574851
epoch 54 iter 71550: loss = 0.9793, smooth loss = 1.1003, ce loss = 0.9793, contrastive loss = 0.0000, lr = 0.00048001155746930777
epoch 55 iter 72875: loss = 1.1958, smooth loss = 1.1165, ce loss = 1.1958, contrastive loss = 0.0000, lr = 0.00046946059322968797
epoch 56 iter 74200: loss = 1.2028, smooth loss = 1.1045, ce loss = 1.2028, contrastive loss = 0.0000, lr = 0.00045885955289993313
epoch 57 iter 75525: loss = 0.9867, smooth loss = 1.0964, ce loss = 0.9867, contrastive loss = 0.0000, lr = 0.0004482160792434408
epoch 58 iter 76850: loss = 1.1343, smooth loss = 1.0647, ce loss = 1.1343, contrastive loss = 0.0000, lr = 0.0004375378456156887
epoch 59 iter 78175: loss = 0.9233, smooth loss = 1.0627, ce loss = 0.9233, contrastive loss = 0.0000, lr = 0.00042683255043216993
epoch 60 iter 79500: loss = 0.9070, smooth loss = 1.0438, ce loss = 0.9070, contrastive loss = 0.0000, lr = 0.0004161079116182619
Save model train-seed-42-FuDan-Scene-32-256-bs-384-lr-0.0008-d_model-512-epoch-120-decay-cos-grad-clip-20-AdamW-wd-0.01-PA-decoder-max-len-40-sup_con-0.0-ce-2.0-temperature-0.15-warm_up-0.025_60_80000
epoch 61 iter 80825: loss = 0.9450, smooth loss = 1.0507, ce loss = 0.9450, contrastive loss = 0.0000, lr = 0.0004053716610450289
epoch 62 iter 82150: loss = 0.7899, smooth loss = 1.0086, ce loss = 0.7899, contrastive loss = 0.0000, lr = 0.0003946315389549712
epoch 63 iter 83475: loss = 0.9737, smooth loss = 1.0026, ce loss = 0.9737, contrastive loss = 0.0000, lr = 0.00038389528838173823
epoch 64 iter 84800: loss = 0.8995, smooth loss = 1.0020, ce loss = 0.8995, contrastive loss = 0.0000, lr = 0.00037317064956783006
epoch 65 iter 86125: loss = 0.8990, smooth loss = 0.9740, ce loss = 0.8990, contrastive loss = 0.0000, lr = 0.0003624653543843114
epoch 66 iter 87450: loss = 1.0501, smooth loss = 0.9775, ce loss = 1.0501, contrastive loss = 0.0000, lr = 0.00035178712075655926
epoch 67 iter 88775: loss = 1.0977, smooth loss = 0.9645, ce loss = 1.0977, contrastive loss = 0.0000, lr = 0.0003411436471000669
epoch 68 iter 90100: loss = 0.8473, smooth loss = 0.9519, ce loss = 0.8473, contrastive loss = 0.0000, lr = 0.0003305426067703122
epoch 69 iter 91425: loss = 1.0364, smooth loss = 0.9543, ce loss = 1.0364, contrastive loss = 0.0000, lr = 0.00031999164253069233
epoch 70 iter 92750: loss = 0.8882, smooth loss = 0.9549, ce loss = 0.8882, contrastive loss = 0.0000, lr = 0.0003094983610425151
epoch 71 iter 94075: loss = 0.8027, smooth loss = 0.9387, ce loss = 0.8027, contrastive loss = 0.0000, lr = 0.0002990703273810167
epoch 72 iter 95400: loss = 0.9439, smooth loss = 0.9212, ce loss = 0.9439, contrastive loss = 0.0000, lr = 0.0002887150595813612
epoch 73 iter 96725: loss = 0.9472, smooth loss = 0.9218, ce loss = 0.9472, contrastive loss = 0.0000, lr = 0.0002784400232185534
epoch 74 iter 98050: loss = 0.8670, smooth loss = 0.9177, ce loss = 0.8670, contrastive loss = 0.0000, lr = 0.0002682526260251721
epoch 75 iter 99375: loss = 0.7562, smooth loss = 0.8906, ce loss = 0.7562, contrastive loss = 0.0000, lr = 0.00025816021255080504
epoch 76 iter 100700: loss = 1.0644, smooth loss = 0.8819, ce loss = 1.0644, contrastive loss = 0.0000, lr = 0.00024817005886703536
epoch 77 iter 102025: loss = 0.7721, smooth loss = 0.8601, ce loss = 0.7721, contrastive loss = 0.0000, lr = 0.0002382893673217962
epoch 78 iter 103350: loss = 0.7118, smooth loss = 0.8415, ce loss = 0.7118, contrastive loss = 0.0000, lr = 0.00022852526134687652
epoch 79 iter 104675: loss = 0.9168, smooth loss = 0.8625, ce loss = 0.9168, contrastive loss = 0.0000, lr = 0.00021888478032232176
epoch 80 iter 106000: loss = 0.8426, smooth loss = 0.8447, ce loss = 0.8426, contrastive loss = 0.0000, lr = 0.0002093748745014289
epoch 81 iter 107325: loss = 0.6818, smooth loss = 0.8269, ce loss = 0.6818, contrastive loss = 0.0000, lr = 0.0002000024000000001
epoch 82 iter 108650: loss = 0.7407, smooth loss = 0.8179, ce loss = 0.7407, contrastive loss = 0.0000, lr = 0.00019077411385346127
epoch 83 iter 109975: loss = 0.7377, smooth loss = 0.8172, ce loss = 0.7377, contrastive loss = 0.0000, lr = 0.00018169666914541447
epoch 84 iter 111300: loss = 0.7133, smooth loss = 0.7895, ce loss = 0.7133, contrastive loss = 0.0000, lr = 0.0001727766102111325
epoch 85 iter 112625: loss = 0.6879, smooth loss = 0.7944, ce loss = 0.6879, contrastive loss = 0.0000, lr = 0.000164020367919455
epoch 86 iter 113950: loss = 0.6099, smooth loss = 0.8005, ce loss = 0.6099, contrastive loss = 0.0000, lr = 0.00015543425503648805
epoch 87 iter 115275: loss = 0.8773, smooth loss = 0.7683, ce loss = 0.8773, contrastive loss = 0.0000, lr = 0.0001470244616744501
epoch 88 iter 116600: loss = 0.7095, smooth loss = 0.7589, ce loss = 0.7095, contrastive loss = 0.0000, lr = 0.00013879705082894204
epoch 89 iter 117925: loss = 0.6336, smooth loss = 0.7636, ce loss = 0.6336, contrastive loss = 0.0000, lr = 0.00013075795400786374
epoch 90 iter 119250: loss = 0.7732, smooth loss = 0.7604, ce loss = 0.7732, contrastive loss = 0.0000, lr = 0.00012291296695512586
Save model train-seed-42-FuDan-Scene-32-256-bs-384-lr-0.0008-d_model-512-epoch-120-decay-cos-grad-clip-20-AdamW-wd-0.01-PA-decoder-max-len-40-sup_con-0.0-ce-2.0-temperature-0.15-warm_up-0.025_90_120000
epoch 91 iter 120575: loss = 0.6551, smooth loss = 0.7478, ce loss = 0.6551, contrastive loss = 0.0000, lr = 0.00011526774547223771
epoch 92 iter 121900: loss = 0.9636, smooth loss = 0.7451, ce loss = 0.9636, contrastive loss = 0.0000, lr = 0.00010782780134078822
epoch 93 iter 123225: loss = 0.6089, smooth loss = 0.7287, ce loss = 0.6089, contrastive loss = 0.0000, lr = 0.00010059849834875659
epoch 94 iter 124550: loss = 0.7795, smooth loss = 0.7382, ce loss = 0.7795, contrastive loss = 0.0000, lr = 9.358504842351783e-05
epoch 95 iter 125875: loss = 0.7207, smooth loss = 0.7140, ce loss = 0.7207, contrastive loss = 0.0000, lr = 8.679250787433099e-05
epoch 96 iter 127200: loss = 0.5984, smooth loss = 0.7097, ce loss = 0.5984, contrastive loss = 0.0000, lr = 8.022577374702106e-05
epoch 97 iter 128525: loss = 0.7974, smooth loss = 0.7227, ce loss = 0.7974, contrastive loss = 0.0000, lr = 7.388958029347893e-05
epoch 98 iter 129850: loss = 0.6606, smooth loss = 0.7031, ce loss = 0.6606, contrastive loss = 0.0000, lr = 6.778849555852853e-05
epoch 99 iter 131175: loss = 0.6213, smooth loss = 0.6960, ce loss = 0.6213, contrastive loss = 0.0000, lr = 6.192691808661902e-05
average data time = 0.0085s, average running time = 0.7900s
epoch 99 iter 131175: eval loss = 0.8622,  ccr = 0.8409,  cwr = 0.7290,  ted = 45720.0000,  ned = 8569.3397,  ted/w = 0.7184, 
Better model found at epoch 99, iter 131175 with accuracy value: 0.7290.
epoch 100 iter 132500: loss = 0.7694, smooth loss = 0.6883, ce loss = 0.7694, contrastive loss = 0.0000, lr = 5.630907375071737e-05
average data time = 0.0085s, average running time = 0.7914s
epoch 100 iter 132500: eval loss = 0.8756,  ccr = 0.8404,  cwr = 0.7263,  ted = 45783.0000,  ned = 8700.5868,  ted/w = 0.7193, 
epoch 101 iter 133825: loss = 0.7320, smooth loss = 0.6790, ce loss = 0.7320, contrastive loss = 0.0000, lr = 5.093901270568848e-05
average data time = 0.0085s, average running time = 0.7926s
epoch 101 iter 133825: eval loss = 0.8681,  ccr = 0.8416,  cwr = 0.7290,  ted = 45339.0000,  ned = 8586.9350,  ted/w = 0.7124, 
Better model found at epoch 101, iter 133825 with accuracy value: 0.7290.
epoch 102 iter 135150: loss = 0.5493, smooth loss = 0.6818, ce loss = 0.5493, contrastive loss = 0.0000, lr = 4.582060646835713e-05
average data time = 0.0085s, average running time = 0.7939s
epoch 102 iter 135150: eval loss = 0.8745,  ccr = 0.8404,  cwr = 0.7273,  ted = 45616.0000,  ned = 8612.7588,  ted/w = 0.7167, 
epoch 103 iter 136475: loss = 0.5990, smooth loss = 0.6844, ce loss = 0.5990, contrastive loss = 0.0000, lr = 4.09575451263587e-05
average data time = 0.0085s, average running time = 0.7951s
epoch 103 iter 136475: eval loss = 0.8732,  ccr = 0.8405,  cwr = 0.7273,  ted = 45605.0000,  ned = 8632.5264,  ted/w = 0.7166, 
epoch 104 iter 137800: loss = 0.6062, smooth loss = 0.6693, ce loss = 0.6062, contrastive loss = 0.0000, lr = 3.635333467779016e-05
average data time = 0.0085s, average running time = 0.7963s
epoch 104 iter 137800: eval loss = 0.8807,  ccr = 0.8407,  cwr = 0.7284,  ted = 45433.0000,  ned = 8625.3718,  ted/w = 0.7139, 
epoch 105 iter 139125: loss = 0.6750, smooth loss = 0.6765, ce loss = 0.6750, contrastive loss = 0.0000, lr = 3.201129450358016e-05
average data time = 0.0085s, average running time = 0.7975s
epoch 105 iter 139125: eval loss = 0.8681,  ccr = 0.8401,  cwr = 0.7272,  ted = 45671.0000,  ned = 8618.8977,  ted/w = 0.7176, 
epoch 106 iter 140450: loss = 0.6465, smooth loss = 0.6668, ce loss = 0.6465, contrastive loss = 0.0000, lr = 2.7934554974397916e-05
average data time = 0.0085s, average running time = 0.7986s
epoch 106 iter 140450: eval loss = 0.8849,  ccr = 0.8410,  cwr = 0.7283,  ted = 45358.0000,  ned = 8574.4255,  ted/w = 0.7127, 
epoch 107 iter 141775: loss = 0.6845, smooth loss = 0.6563, ce loss = 0.6845, contrastive loss = 0.0000, lr = 2.412605519382993e-05
average data time = 0.0085s, average running time = 0.7998s
epoch 107 iter 141775: eval loss = 0.8738,  ccr = 0.8409,  cwr = 0.7287,  ted = 45411.0000,  ned = 8589.4598,  ted/w = 0.7135, 
epoch 108 iter 143100: loss = 0.5185, smooth loss = 0.6648, ce loss = 0.5185, contrastive loss = 0.0000, lr = 2.0588540879448922e-05
average data time = 0.0085s, average running time = 0.8010s
epoch 108 iter 143100: eval loss = 0.8773,  ccr = 0.8410,  cwr = 0.7295,  ted = 45237.0000,  ned = 8545.8059,  ted/w = 0.7108, 
Better model found at epoch 108, iter 143100 with accuracy value: 0.7295.
epoch 109 iter 144425: loss = 0.6268, smooth loss = 0.6694, ce loss = 0.6268, contrastive loss = 0.0000, lr = 1.7324562383303276e-05
average data time = 0.0085s, average running time = 0.8021s
epoch 109 iter 144425: eval loss = 0.8753,  ccr = 0.8414,  cwr = 0.7301,  ted = 45324.0000,  ned = 8561.0777,  ted/w = 0.7121, 
Better model found at epoch 109, iter 144425 with accuracy value: 0.7301.
epoch 110 iter 145750: loss = 0.8559, smooth loss = 0.6601, ce loss = 0.8559, contrastive loss = 0.0000, lr = 1.4336472853254332e-05
average data time = 0.0085s, average running time = 0.8033s
epoch 110 iter 145750: eval loss = 0.8812,  ccr = 0.8412,  cwr = 0.7293,  ted = 45279.0000,  ned = 8561.7808,  ted/w = 0.7114, 
epoch 111 iter 147075: loss = 0.4998, smooth loss = 0.6597, ce loss = 0.4998, contrastive loss = 0.0000, lr = 1.1626426536487078e-05
average data time = 0.0085s, average running time = 0.8044s
epoch 111 iter 147075: eval loss = 0.8781,  ccr = 0.8415,  cwr = 0.7294,  ted = 45193.0000,  ned = 8576.8807,  ted/w = 0.7101, 
epoch 112 iter 148400: loss = 0.6773, smooth loss = 0.6532, ce loss = 0.6773, contrastive loss = 0.0000, lr = 9.196377226417202e-06
average data time = 0.0085s, average running time = 0.8054s
epoch 112 iter 148400: eval loss = 0.8763,  ccr = 0.8420,  cwr = 0.7305,  ted = 44969.0000,  ned = 8527.4074,  ted/w = 0.7066, 
Better model found at epoch 112, iter 148400 with accuracy value: 0.7305.
epoch 113 iter 149725: loss = 0.7217, smooth loss = 0.6685, ce loss = 0.7217, contrastive loss = 0.0000, lr = 7.04807685411396e-06
average data time = 0.0085s, average running time = 0.8065s
epoch 113 iter 149725: eval loss = 0.8747,  ccr = 0.8416,  cwr = 0.7298,  ted = 45134.0000,  ned = 8564.6758,  ted/w = 0.7092, 
epoch 114 iter 151050: loss = 0.7421, smooth loss = 0.6567, ce loss = 0.7421, contrastive loss = 0.0000, lr = 5.183074225255083e-06
average data time = 0.0085s, average running time = 0.8075s
epoch 114 iter 151050: eval loss = 0.8766,  ccr = 0.8419,  cwr = 0.7300,  ted = 45115.0000,  ned = 8541.5843,  ted/w = 0.7089, 
epoch 115 iter 152375: loss = 0.6559, smooth loss = 0.6416, ce loss = 0.6559, contrastive loss = 0.0000, lr = 3.6027139035234053e-06
average data time = 0.0085s, average running time = 0.8085s
epoch 115 iter 152375: eval loss = 0.8758,  ccr = 0.8422,  cwr = 0.7304,  ted = 45049.0000,  ned = 8541.0000,  ted/w = 0.7078, 
epoch 116 iter 153700: loss = 0.6371, smooth loss = 0.6529, ce loss = 0.6371, contrastive loss = 0.0000, lr = 2.308135241251002e-06
average data time = 0.0085s, average running time = 0.8093s
epoch 116 iter 153700: eval loss = 0.8757,  ccr = 0.8418,  cwr = 0.7300,  ted = 45112.0000,  ned = 8551.0191,  ted/w = 0.7088, 
epoch 117 iter 155025: loss = 0.7382, smooth loss = 0.6497, ce loss = 0.7382, contrastive loss = 0.0000, lr = 1.300271558009043e-06
average data time = 0.0085s, average running time = 0.8102s
epoch 117 iter 155025: eval loss = 0.8786,  ccr = 0.8421,  cwr = 0.7303,  ted = 45002.0000,  ned = 8528.9644,  ted/w = 0.7071, 
epoch 118 iter 156350: loss = 0.4907, smooth loss = 0.6559, ce loss = 0.4907, contrastive loss = 0.0000, lr = 5.79849467736198e-07
average data time = 0.0085s, average running time = 0.8110s
epoch 118 iter 156350: eval loss = 0.8798,  ccr = 0.8418,  cwr = 0.7300,  ted = 45101.0000,  ned = 8551.0594,  ted/w = 0.7086, 
epoch 119 iter 157675: loss = 0.7144, smooth loss = 0.6438, ce loss = 0.7144, contrastive loss = 0.0000, lr = 1.4738835489012343e-07
average data time = 0.0085s, average running time = 0.8119s
epoch 119 iter 157675: eval loss = 0.8766,  ccr = 0.8419,  cwr = 0.7302,  ted = 45103.0000,  ned = 8544.4981,  ted/w = 0.7087, 
